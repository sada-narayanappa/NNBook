{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython import display\n",
    "pd.options.display.max_rows = 8\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (16, 5)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "#dfn.plot(subplots=True)\n",
    "#trainPercent = .7\n",
    "tf.random.set_seed(13)\n",
    "#--------------------------------------------------------------------------------\n",
    "def get_data(dataset, target, start, end, history, target_size, skip=1,oneStep=False):\n",
    "    data   = []\n",
    "    labels = []\n",
    "\n",
    "    start = start + history\n",
    "    if end is None:\n",
    "        end = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start, end):\n",
    "        #print(f\"++ {i}  {start} {end_index} \\r\", end=\"\")\n",
    "        indices = range(i-history, i, skip)\n",
    "        \n",
    "        dt = np.reshape(dataset[indices], ( -1, dataset.shape[-1]))\n",
    "        data.append(dt)\n",
    "\n",
    "        if oneStep:\n",
    "            labels.append(target[i+target_size])\n",
    "        else:\n",
    "            labels.append(target[i:i+target_size])\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# target: column to predict\n",
    "# history      : how long of history to look\n",
    "# target_ahead : how much in the future \"target\" is predicted\n",
    "#      =>confusing!! if values right next to it is predicted, it is =0\n",
    "#      if say, you lke to predict 5 time steps aheads then it is 5\n",
    "#\n",
    "# single_oneStepstep : # predictions\n",
    "# pct         : percentage split or a number of samples\n",
    "def get_split(df, history,target=None, pct=0.7, \n",
    "                  target_ahead=0, skip=1, oneStep=True):\n",
    "\n",
    "    TRAIN_SPLIT = int(len(df) * trainPercent) if (pct < 1) else pct\n",
    "    target = target if target else df.columns[0]\n",
    "    \n",
    "    print(f\"Training_split: {TRAIN_SPLIT}, target: {target}\")\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    dfs = scaler.fit(df[:TRAIN_SPLIT])\n",
    "    dfs.mean_, dfs.scale_\n",
    "    dfns = (df-dfs.mean_)/dfs.scale_ \n",
    "    \n",
    "    ds = dfns.values\n",
    "    xtrn, ytrn = get_data(ds, dfns[target].values, 0, TRAIN_SPLIT,\n",
    "                        history, target_ahead,skip,True)\n",
    "    xval, yval = get_data(ds, dfns[target].values, TRAIN_SPLIT, None,\n",
    "                        history, target_ahead,skip,True)\n",
    "    \n",
    "    return scaler, dfns, xtrn, ytrn, xval, yval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>rho (g/m**3)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:10:00</th>\n",
       "      <td>-8.02</td>\n",
       "      <td>996.52</td>\n",
       "      <td>1307.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:20:00</th>\n",
       "      <td>-8.41</td>\n",
       "      <td>996.57</td>\n",
       "      <td>1309.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:30:00</th>\n",
       "      <td>-8.51</td>\n",
       "      <td>996.53</td>\n",
       "      <td>1310.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:40:00</th>\n",
       "      <td>-8.31</td>\n",
       "      <td>996.51</td>\n",
       "      <td>1309.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 10:30:00</th>\n",
       "      <td>0.50</td>\n",
       "      <td>977.94</td>\n",
       "      <td>1242.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 10:40:00</th>\n",
       "      <td>0.95</td>\n",
       "      <td>977.88</td>\n",
       "      <td>1240.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 10:50:00</th>\n",
       "      <td>1.10</td>\n",
       "      <td>977.82</td>\n",
       "      <td>1239.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 11:00:00</th>\n",
       "      <td>1.13</td>\n",
       "      <td>977.71</td>\n",
       "      <td>1239.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     T (degC)  p (mbar)  rho (g/m**3)\n",
       "Date Time                                            \n",
       "2009-01-01 00:10:00     -8.02    996.52       1307.75\n",
       "2009-01-01 00:20:00     -8.41    996.57       1309.80\n",
       "2009-01-01 00:30:00     -8.51    996.53       1310.24\n",
       "2009-01-01 00:40:00     -8.31    996.51       1309.19\n",
       "...                       ...       ...           ...\n",
       "2010-11-25 10:30:00      0.50    977.94       1242.25\n",
       "2010-11-25 10:40:00      0.95    977.88       1240.10\n",
       "2010-11-25 10:50:00      1.10    977.82       1239.34\n",
       "2010-11-25 11:00:00      1.13    977.71       1239.05\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Data\n",
    "#del dfn1\n",
    "if ( \"dfn1\" not in globals()):\n",
    "    csv_path = 'jena_climate_2009_2016.csv.zip'\n",
    "    df = pd.read_csv(csv_path, nrows=100000)\n",
    "    df['Date Time'] = pd.to_datetime( df['Date Time'] )\n",
    "\n",
    "    dfn1= df[['T (degC)']].copy()\n",
    "    dfn1.index = df['Date Time']\n",
    "\n",
    "    dfn2= df[['T (degC)', 'p (mbar)', 'rho (g/m**3)']].copy()\n",
    "    dfn2.index = df['Date Time']\n",
    "\n",
    "    dfn = dfn2\n",
    "    dfn\n",
    "    \n",
    "dfn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[  -8.02,  996.52, 1307.75],\n",
       "         [  -8.41,  996.57, 1309.8 ],\n",
       "         [  -8.51,  996.53, 1310.24],\n",
       "         [  -8.31,  996.51, 1309.19],\n",
       "         [  -8.27,  996.51, 1309.  ]],\n",
       " \n",
       "        [[  -8.41,  996.57, 1309.8 ],\n",
       "         [  -8.51,  996.53, 1310.24],\n",
       "         [  -8.31,  996.51, 1309.19],\n",
       "         [  -8.27,  996.51, 1309.  ],\n",
       "         [  -8.05,  996.5 , 1307.86]],\n",
       " \n",
       "        [[  -8.51,  996.53, 1310.24],\n",
       "         [  -8.31,  996.51, 1309.19],\n",
       "         [  -8.27,  996.51, 1309.  ],\n",
       "         [  -8.05,  996.5 , 1307.86],\n",
       "         [  -7.62,  996.5 , 1305.68]]]), array([[-8.05, -7.62, -7.62, -7.91],\n",
       "        [-7.62, -7.62, -7.91, -8.43],\n",
       "        [-7.62, -7.91, -8.43, -8.76]]), (95, 5, 3))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar=dfn2.columns[0]\n",
    "#get_data(dataset, target, start, end, history, target_size, skip=1,oneStep=False):\n",
    "X, y = get_data(dfn2.values, dfn2[tar].values, 0, 100, 5, 4, skip=1,oneStep=False)\n",
    "X[0:3], y[0:3], X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['T (degC)', 'p (mbar)', 'rho (g/m**3)'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 8,\n",
      "batch --size=2\n",
      "[[[10, 15], [20, 25]]] => [[30]]\n",
      "[[[20, 25], [30, 35]]] => [[40]]\n",
      "[[[30, 35], [40, 45]]] => [[50]]\n",
      "[[[40, 45], [50, 55]]] => [[60]]\n",
      "[[[50, 55], [60, 65]]] => [[70]]\n",
      "[[[60, 65], [70, 75]]] => [[80]]\n",
      "[[[70, 75], [80, 85]]] => [[90]]\n",
      "[[[80, 85], [90, 95]]] => [[100]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "# define dataset\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95, 105])\n",
    "# reshape series\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2))\n",
    "#print(dataset)\n",
    "generator2 = TimeseriesGenerator(dataset, in_seq1, length=2, batch_size=1)\n",
    "print(f'Samples: {len(generator2)},')\n",
    "print('batch --size=2')    \n",
    "for i in range(len(generator2)):\n",
    "    x, y = generator2[i]\n",
    "    xx = [[list(c) for c in cc] for cc in x]\n",
    "    yy = [list(c) for c in y]\n",
    "    print(f'{xx} => {yy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e346104/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[10, 15],\n",
       "         [20, 25],\n",
       "         [30, 35],\n",
       "         [40, 45],\n",
       "         [50, 55]],\n",
       " \n",
       "        [[20, 25],\n",
       "         [30, 35],\n",
       "         [40, 45],\n",
       "         [50, 55],\n",
       "         [60, 65]],\n",
       " \n",
       "        [[30, 35],\n",
       "         [40, 45],\n",
       "         [50, 55],\n",
       "         [60, 65],\n",
       "         [70, 75]]]), array([array([[60],\n",
       "        [70],\n",
       "        [80],\n",
       "        [90]]),\n",
       "        array([[ 70],\n",
       "        [ 80],\n",
       "        [ 90],\n",
       "        [100]]),\n",
       "        array([[ 80],\n",
       "        [ 90],\n",
       "        [100]])], dtype=object), (5, 5, 2))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get_data(dataset, target, start, end, history, target_size, skip=1,oneStep=False):\n",
    "X, y = get_data(dataset, in_seq1, 0, 10, 5, 4, skip=1,oneStep=False)\n",
    "X[0:3], y[0:3], X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0]\n",
      "  [2]\n",
      "  [4]\n",
      "  [6]\n",
      "  [8]]\n",
      "\n",
      " [[1]\n",
      "  [3]\n",
      "  [5]\n",
      "  [7]\n",
      "  [9]]] => [[10]\n",
      " [11]]\n",
      "\n",
      "\n",
      "For Nice printing\n",
      "[[[0], [2], [4], [6], [8]], [[1], [3], [5], [7], [9]]] => [[10], [11]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import numpy as np\n",
    "data = array([[i] for i in range(50)])\n",
    "targets = array([[i] for i in range(50)])\n",
    "data_gen = TimeseriesGenerator(data, targets,\n",
    "                               length=10, sampling_rate=2,\n",
    "                               batch_size=2)\n",
    "'''assert len(data_gen) == 20\n",
    "batch_0 = data_gen[0]\n",
    "x, y = batch_0\n",
    "assert np.array_equal(x,\n",
    "                      np.array([[[0], [2], [4], [6], [8]],\n",
    "                                [[1], [3], [5], [7], [9]]]))\n",
    "assert np.array_equal(y,\n",
    "                      np.array([[10], [11]]))\n",
    "\n",
    "data.shape'''\n",
    "\n",
    "for i in range(len(data_gen)):\n",
    "    x, y = data_gen[i]\n",
    "    print(f'{x} => {y}\\n')\n",
    "    \n",
    "    #Just for printing purposes only\n",
    "    xx = [[list(c) for c in cc] for cc in x]\n",
    "    yy = [list(c) for c in y]\n",
    "    print(f'\\nFor Nice printing\\n{xx} => {yy}')\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesLSTM:\n",
    "    '''\n",
    "    df    : data frame\n",
    "    UNITS1: # units in layer1 of LSTM\n",
    "    UNITS2: # units in layer2 of LSTM, 0 if one layer\n",
    "    nfeats: number of features\n",
    "    target_ahead and npreds = how far ahead to predict, single or multiple\n",
    "    '''\n",
    "    def __init__(self, history, nfeats, target_ahead = 0, skip=1,\n",
    "                 UNITS1=32, UNITS2=0, npreds=1, verbose=1,\n",
    "                 OPTIMIZER = 'adam', model_file=\"temp.hd5\"\n",
    "                ):\n",
    "        self.UNITS1       = UNITS1 or 32\n",
    "        self.UNITS2       = UNITS2 or 0\n",
    "        self.history      = history\n",
    "        self.npreds       = npreds\n",
    "        self.target_ahead = target_ahead\n",
    "        self.model_file   = model_file\n",
    "        self.skip         = skip\n",
    "        \n",
    "        self.nfeats       = nfeats\n",
    "        self.BATCH_SIZE   = 256\n",
    "        self.BUFFER_SIZE  = 10000\n",
    "        self.EPOCHS       = 20\n",
    "        self.LOSS         = \"mae\"\n",
    "        #self.OPTIMIZER    = tf.keras.optimizers.RMSprop(clipvalue=1.0)\n",
    "        self.OPTIMIZER    = OPTIMIZER\n",
    "        self.EVAL_INTERVAL= 200\n",
    "        self.VAL_STEPS    = 50\n",
    "        self.V            = verbose\n",
    "\n",
    "    ''' This just builds a model '''\n",
    "    def model(self):\n",
    "        m = tf.keras.models.Sequential()\n",
    "        \n",
    "        hist =int(self.history/self.skip)\n",
    "        m.add(LSTM(self.UNITS1, return_sequences= (self.npreds >1),\n",
    "                        input_shape=(hist, self.nfeats) ))\n",
    "        if(self.UNITS2):\n",
    "            m.add(tf.keras.layers.LSTM(self.UNITS2, activation='relu'))\n",
    "        m.add(tf.keras.layers.Dense(self.npreds))\n",
    "        m.compile(optimizer = self.OPTIMIZER, loss=self.LOSS)\n",
    "        \n",
    "        self.model = m\n",
    "        return m\n",
    "    \n",
    "    def prepare(self, dfn,target=None, pct=0.7):\n",
    "        self.DFN    = dfn;\n",
    "        self.target = target\n",
    "        \n",
    "        ret = get_split( dfn, self.history, target, pct,\n",
    "                        self.target_ahead, self.skip,\n",
    "                        oneStep = (self.npreds <= 1) )\n",
    "\n",
    "        scaler, df, xtrn, ytrn, xval, yval = ret\n",
    "        \n",
    "        trn = tf.data.Dataset.from_tensor_slices((xtrn, ytrn))\n",
    "        trn = trn.cache().shuffle(self.BUFFER_SIZE).batch(\n",
    "                self.BATCH_SIZE).repeat()\n",
    "\n",
    "        val = tf.data.Dataset.from_tensor_slices((xval, yval))\n",
    "        val = val.batch(self.BATCH_SIZE).repeat()\n",
    "\n",
    "        self.scaler, self.df, self.xtrn, self.ytrn,  \\\n",
    "                                self.xval, self.yval = ret\n",
    "        self.trn, self.val = trn, val\n",
    "        \n",
    "        return self.DFN, self.skip, self.target, ret, trn, val\n",
    " \n",
    "    def prepSet(self,prepped):\n",
    "        self.DFN, self.skip, self.target, ret, self.trn, self.val = prepped\n",
    "        self.scaler, self.df, self.xtrn, self.ytrn,  \\\n",
    "                                self.xval, self.yval = ret\n",
    "    \n",
    "    def fit(self, epochs=None, verbose=None):\n",
    "        \n",
    "        epochs = epochs  or self.EPOCHS\n",
    "        verbose= verbose or self.V\n",
    "        \n",
    "        trn, val = self.trn, self.val\n",
    "        self.model.fit(trn, verbose=verbose, epochs=epochs,\n",
    "                steps_per_epoch = self.EVAL_INTERVAL,\n",
    "                validation_data = val, validation_steps=self.VAL_STEPS,\n",
    "                      callbacks=None)\n",
    "        \n",
    "    def save(self):\n",
    "        self.model.save(self.model_file)\n",
    "\n",
    "    def load(self):\n",
    "        self.model = load_model(self.model_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictPlot_(start    , howmany, history      , npreds  ,\n",
    "                 DFN      , model   , target_ahead , scaler, target, skip=1, title=\"\",**kwargs):\n",
    "    \n",
    "    ds1   = DFN[start:start+howmany+history+target_ahead].values\n",
    "\n",
    "    xp, yp = get_data(ds1, ds1[:, target], 0, None,\n",
    "                         history, target_ahead, skip, npreds<=1)\n",
    "\n",
    "    if (scaler is not None):\n",
    "        for i,x  in enumerate(xp):\n",
    "            xp[i] = scaler.transform(xp[i])\n",
    "\n",
    "    yh1= model.predict(xp)\n",
    "    yh = yh1\n",
    "    if (scaler is not None):\n",
    "        #yh = scaler.inverse_transform(yh1)\n",
    "        yh = yh1 * scaler.scale_[target]\n",
    "        yh = yh  + scaler.mean_[target]\n",
    "\n",
    "    #print(xtrn[0], ytrn[0],dfn.iloc[0])\n",
    "    target = dfn.columns[0]\n",
    "\n",
    "\n",
    "    plt.plot(yp[:,0], marker=\".\", label = \"y\")\n",
    "    plt.plot(yh, marker=\"x\", label = \"$\\hat{y}$\")\n",
    "    for i in range (yh.shape[0]):\n",
    "        pass\n",
    "        #plt.plot(yh[:,i], marker=\"x\", label= f\"predicted: {i}\")\n",
    "    \n",
    "    idx= DFN.index[start+history+target_ahead : start+howmany+history+target_ahead]\n",
    "    intv = max(1, int(len(idx)/10) )\n",
    "    plt.xticks(range(0,len(yh),10), idx, rotation=45)\n",
    "    \n",
    "    assert len(idx) == len(yp), \"Hmmm Something calculations dont jibe!!!\"\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.grid(b=\"on\")\n",
    "    plt.legend()\n",
    "    #pr = lstm.predict(xtrn[1].reshape(1,xtrn[0\n",
    "    return xp,yp, yh, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\"dfn1\" not in globals()):\n",
    "    csv_path = 'jena_climate_2009_2016.csv.zip'\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['Date Time'] = pd.to_datetime( df['Date Time'] )\n",
    "\n",
    "    dfn1= df[['T (degC)']].copy()\n",
    "    dfn1.index = df['Date Time']\n",
    "\n",
    "    dfn2= df[['T (degC)', 'p (mbar)', 'rho (g/m**3)']].copy()\n",
    "    dfn2.index = df['Date Time']\n",
    "\n",
    "    dfn = dfn2\n",
    "    dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_split: 300000, target: T (degC)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 100000 is out of bounds for axis 0 with size 100000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-39a5da150374>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mprep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfn1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mlmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-290ff18a281f>\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, dfn, target, pct)\u001b[0m\n\u001b[1;32m     51\u001b[0m         ret = get_split( dfn, self.history, target, pct,\n\u001b[1;32m     52\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_ahead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                         oneStep = (self.npreds <= 1) )\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-d17d1df8d946>\u001b[0m in \u001b[0;36mget_split\u001b[0;34m(df, history, target, pct, target_ahead, skip, oneStep)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     xtrn, ytrn = get_data(ds, dfns[target].values, 0, TRAIN_SPLIT,\n\u001b[0;32m---> 65\u001b[0;31m                         history, target_ahead,skip,True)\n\u001b[0m\u001b[1;32m     66\u001b[0m     xval, yval = get_data(ds, dfns[target].values, TRAIN_SPLIT, None,\n\u001b[1;32m     67\u001b[0m                         history, target_ahead,skip,True)\n",
      "\u001b[0;32m<ipython-input-18-d17d1df8d946>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(dataset, target, start, end, history, target_size, skip, oneStep)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moneStep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 100000 is out of bounds for axis 0 with size 100000"
     ]
    }
   ],
   "source": [
    "mpl.rcParams['figure.figsize'] = (16, 5)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "lmodel = TimeSeriesLSTM(history=20, nfeats=1, target_ahead=0, skip=1,\n",
    "                 UNITS1=32, UNITS2=0, npreds=1, verbose=0)\n",
    "\n",
    "lmodel.model()\n",
    "preload=0\n",
    "if (preload):\n",
    "    lmodel.load()\n",
    "    lmodel.prepSet(prep)\n",
    "else:\n",
    "    prep=lmodel.prepare(dfn1,0, 300000)\n",
    "    lmodel.save()\n",
    "    \n",
    "predictPlot_(0, 100, title=\"Before Train\", **vars(lmodel) );\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predictPlot_() missing 1 required positional argument: 'scaler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-053a00851b79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpredictPlot_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{i}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: predictPlot_() missing 1 required positional argument: 'scaler'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = datetime.datetime.now()\n",
    "for i in range(10):\n",
    "    display.clear_output(wait=True)\n",
    "    plt.clf()\n",
    "    predictPlot_(0, 100, title=f\"{i}\", **vars(lmodel) )\n",
    "    plt.show()\n",
    "    display.display(plt.gcf())\n",
    "    lmodel.fit(1,1)\n",
    "t2 = datetime.datetime.now()\n",
    "print(f\"++ time : {t2-t1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TimeSeriesLSTM' object has no attribute 'scaler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3787c0b65f05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msimple_lstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"simple_lstm_model.hd5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictPlot_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDFN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimple_lstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Simple LSTM Model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'TimeSeriesLSTM' object has no attribute 'scaler'"
     ]
    }
   ],
   "source": [
    "simple_lstm_model = load_model(\"simple_lstm_model.hd5\")\n",
    "predictPlot_(0, 100, 20,1,lmodel.DFN, simple_lstm_model, 0, lmodel.scaler, 0, 1,\"Simple LSTM Model\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# MultiVariate Single Step Predictions\n",
    "\n",
    "This uses multiple features dfn2 has 3 features we will use to train;\n",
    "We will also predict temperature far ahead in the future say 12 hours ahead.\n",
    "\n",
    "We will use 5 days of historical data with 3 features. Since temperature dont change often we down sample \n",
    "the entire data set to hours instead of 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>rho (g/m**3)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:10:00</th>\n",
       "      <td>-8.02</td>\n",
       "      <td>996.52</td>\n",
       "      <td>1307.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:20:00</th>\n",
       "      <td>-8.41</td>\n",
       "      <td>996.57</td>\n",
       "      <td>1309.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:30:00</th>\n",
       "      <td>-8.51</td>\n",
       "      <td>996.53</td>\n",
       "      <td>1310.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:40:00</th>\n",
       "      <td>-8.31</td>\n",
       "      <td>996.51</td>\n",
       "      <td>1309.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:50:00</th>\n",
       "      <td>-8.27</td>\n",
       "      <td>996.51</td>\n",
       "      <td>1309.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 01:00:00</th>\n",
       "      <td>-8.05</td>\n",
       "      <td>996.50</td>\n",
       "      <td>1307.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 01:10:00</th>\n",
       "      <td>-7.62</td>\n",
       "      <td>996.50</td>\n",
       "      <td>1305.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 01:20:00</th>\n",
       "      <td>-7.62</td>\n",
       "      <td>996.50</td>\n",
       "      <td>1305.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 01:30:00</th>\n",
       "      <td>-7.91</td>\n",
       "      <td>996.50</td>\n",
       "      <td>1307.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 01:40:00</th>\n",
       "      <td>-8.43</td>\n",
       "      <td>996.53</td>\n",
       "      <td>1309.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 01:50:00</th>\n",
       "      <td>-8.76</td>\n",
       "      <td>996.62</td>\n",
       "      <td>1311.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 02:00:00</th>\n",
       "      <td>-8.88</td>\n",
       "      <td>996.62</td>\n",
       "      <td>1312.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 02:10:00</th>\n",
       "      <td>-8.85</td>\n",
       "      <td>996.63</td>\n",
       "      <td>1312.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 02:20:00</th>\n",
       "      <td>-8.83</td>\n",
       "      <td>996.74</td>\n",
       "      <td>1312.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 02:30:00</th>\n",
       "      <td>-8.66</td>\n",
       "      <td>996.81</td>\n",
       "      <td>1311.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 02:40:00</th>\n",
       "      <td>-8.66</td>\n",
       "      <td>996.81</td>\n",
       "      <td>1311.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 02:50:00</th>\n",
       "      <td>-8.70</td>\n",
       "      <td>996.86</td>\n",
       "      <td>1311.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 03:00:00</th>\n",
       "      <td>-8.81</td>\n",
       "      <td>996.84</td>\n",
       "      <td>1312.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 03:10:00</th>\n",
       "      <td>-8.84</td>\n",
       "      <td>996.87</td>\n",
       "      <td>1312.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 03:20:00</th>\n",
       "      <td>-8.94</td>\n",
       "      <td>996.97</td>\n",
       "      <td>1313.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 03:30:00</th>\n",
       "      <td>-8.94</td>\n",
       "      <td>997.08</td>\n",
       "      <td>1313.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 03:40:00</th>\n",
       "      <td>-8.86</td>\n",
       "      <td>997.10</td>\n",
       "      <td>1312.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 03:50:00</th>\n",
       "      <td>-8.99</td>\n",
       "      <td>997.06</td>\n",
       "      <td>1313.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 04:00:00</th>\n",
       "      <td>-9.05</td>\n",
       "      <td>996.99</td>\n",
       "      <td>1313.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 04:10:00</th>\n",
       "      <td>-9.23</td>\n",
       "      <td>997.05</td>\n",
       "      <td>1314.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 04:20:00</th>\n",
       "      <td>-9.49</td>\n",
       "      <td>997.11</td>\n",
       "      <td>1316.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 04:30:00</th>\n",
       "      <td>-9.50</td>\n",
       "      <td>997.19</td>\n",
       "      <td>1316.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 04:40:00</th>\n",
       "      <td>-9.35</td>\n",
       "      <td>997.24</td>\n",
       "      <td>1315.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 04:50:00</th>\n",
       "      <td>-9.47</td>\n",
       "      <td>997.37</td>\n",
       "      <td>1316.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 05:00:00</th>\n",
       "      <td>-9.63</td>\n",
       "      <td>997.46</td>\n",
       "      <td>1317.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 06:10:00</th>\n",
       "      <td>-2.30</td>\n",
       "      <td>978.44</td>\n",
       "      <td>1255.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 06:20:00</th>\n",
       "      <td>-2.19</td>\n",
       "      <td>978.40</td>\n",
       "      <td>1255.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 06:30:00</th>\n",
       "      <td>-2.28</td>\n",
       "      <td>978.31</td>\n",
       "      <td>1255.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 06:40:00</th>\n",
       "      <td>-2.26</td>\n",
       "      <td>978.25</td>\n",
       "      <td>1255.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 06:50:00</th>\n",
       "      <td>-2.18</td>\n",
       "      <td>978.28</td>\n",
       "      <td>1255.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 07:00:00</th>\n",
       "      <td>-2.19</td>\n",
       "      <td>978.20</td>\n",
       "      <td>1255.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 07:10:00</th>\n",
       "      <td>-2.23</td>\n",
       "      <td>978.07</td>\n",
       "      <td>1255.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 07:20:00</th>\n",
       "      <td>-2.22</td>\n",
       "      <td>978.07</td>\n",
       "      <td>1255.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 07:30:00</th>\n",
       "      <td>-2.13</td>\n",
       "      <td>978.07</td>\n",
       "      <td>1254.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 07:40:00</th>\n",
       "      <td>-2.11</td>\n",
       "      <td>978.08</td>\n",
       "      <td>1254.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 07:50:00</th>\n",
       "      <td>-2.09</td>\n",
       "      <td>978.07</td>\n",
       "      <td>1254.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 08:00:00</th>\n",
       "      <td>-1.95</td>\n",
       "      <td>978.08</td>\n",
       "      <td>1253.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 08:10:00</th>\n",
       "      <td>-1.85</td>\n",
       "      <td>978.08</td>\n",
       "      <td>1253.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 08:20:00</th>\n",
       "      <td>-1.78</td>\n",
       "      <td>978.10</td>\n",
       "      <td>1253.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 08:30:00</th>\n",
       "      <td>-1.70</td>\n",
       "      <td>978.19</td>\n",
       "      <td>1252.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 08:40:00</th>\n",
       "      <td>-1.54</td>\n",
       "      <td>978.19</td>\n",
       "      <td>1252.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 08:50:00</th>\n",
       "      <td>-1.43</td>\n",
       "      <td>978.19</td>\n",
       "      <td>1251.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 09:00:00</th>\n",
       "      <td>-1.32</td>\n",
       "      <td>978.19</td>\n",
       "      <td>1251.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 09:10:00</th>\n",
       "      <td>-1.21</td>\n",
       "      <td>978.19</td>\n",
       "      <td>1250.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 09:20:00</th>\n",
       "      <td>-1.22</td>\n",
       "      <td>978.19</td>\n",
       "      <td>1250.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 09:30:00</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>978.17</td>\n",
       "      <td>1250.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 09:40:00</th>\n",
       "      <td>-0.90</td>\n",
       "      <td>978.09</td>\n",
       "      <td>1248.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 09:50:00</th>\n",
       "      <td>-0.77</td>\n",
       "      <td>978.08</td>\n",
       "      <td>1248.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 10:00:00</th>\n",
       "      <td>-0.73</td>\n",
       "      <td>978.07</td>\n",
       "      <td>1248.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 10:10:00</th>\n",
       "      <td>-0.62</td>\n",
       "      <td>978.04</td>\n",
       "      <td>1247.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 10:20:00</th>\n",
       "      <td>-0.30</td>\n",
       "      <td>977.96</td>\n",
       "      <td>1245.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 10:30:00</th>\n",
       "      <td>0.50</td>\n",
       "      <td>977.94</td>\n",
       "      <td>1242.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 10:40:00</th>\n",
       "      <td>0.95</td>\n",
       "      <td>977.88</td>\n",
       "      <td>1240.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 10:50:00</th>\n",
       "      <td>1.10</td>\n",
       "      <td>977.82</td>\n",
       "      <td>1239.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 11:00:00</th>\n",
       "      <td>1.13</td>\n",
       "      <td>977.71</td>\n",
       "      <td>1239.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     T (degC)  p (mbar)  rho (g/m**3)\n",
       "Date Time                                            \n",
       "2009-01-01 00:10:00     -8.02    996.52       1307.75\n",
       "2009-01-01 00:20:00     -8.41    996.57       1309.80\n",
       "2009-01-01 00:30:00     -8.51    996.53       1310.24\n",
       "2009-01-01 00:40:00     -8.31    996.51       1309.19\n",
       "2009-01-01 00:50:00     -8.27    996.51       1309.00\n",
       "2009-01-01 01:00:00     -8.05    996.50       1307.86\n",
       "2009-01-01 01:10:00     -7.62    996.50       1305.68\n",
       "2009-01-01 01:20:00     -7.62    996.50       1305.69\n",
       "2009-01-01 01:30:00     -7.91    996.50       1307.17\n",
       "2009-01-01 01:40:00     -8.43    996.53       1309.85\n",
       "2009-01-01 01:50:00     -8.76    996.62       1311.64\n",
       "2009-01-01 02:00:00     -8.88    996.62       1312.25\n",
       "2009-01-01 02:10:00     -8.85    996.63       1312.11\n",
       "2009-01-01 02:20:00     -8.83    996.74       1312.15\n",
       "2009-01-01 02:30:00     -8.66    996.81       1311.37\n",
       "2009-01-01 02:40:00     -8.66    996.81       1311.38\n",
       "2009-01-01 02:50:00     -8.70    996.86       1311.64\n",
       "2009-01-01 03:00:00     -8.81    996.84       1312.18\n",
       "2009-01-01 03:10:00     -8.84    996.87       1312.37\n",
       "2009-01-01 03:20:00     -8.94    996.97       1313.01\n",
       "2009-01-01 03:30:00     -8.94    997.08       1313.15\n",
       "2009-01-01 03:40:00     -8.86    997.10       1312.78\n",
       "2009-01-01 03:50:00     -8.99    997.06       1313.39\n",
       "2009-01-01 04:00:00     -9.05    996.99       1313.61\n",
       "2009-01-01 04:10:00     -9.23    997.05       1314.62\n",
       "2009-01-01 04:20:00     -9.49    997.11       1316.02\n",
       "2009-01-01 04:30:00     -9.50    997.19       1316.16\n",
       "2009-01-01 04:40:00     -9.35    997.24       1315.47\n",
       "2009-01-01 04:50:00     -9.47    997.37       1316.25\n",
       "2009-01-01 05:00:00     -9.63    997.46       1317.19\n",
       "...                       ...       ...           ...\n",
       "2010-11-25 06:10:00     -2.30    978.44       1255.92\n",
       "2010-11-25 06:20:00     -2.19    978.40       1255.36\n",
       "2010-11-25 06:30:00     -2.28    978.31       1255.67\n",
       "2010-11-25 06:40:00     -2.26    978.25       1255.52\n",
       "2010-11-25 06:50:00     -2.18    978.28       1255.16\n",
       "2010-11-25 07:00:00     -2.19    978.20       1255.10\n",
       "2010-11-25 07:10:00     -2.23    978.07       1255.14\n",
       "2010-11-25 07:20:00     -2.22    978.07       1255.10\n",
       "2010-11-25 07:30:00     -2.13    978.07       1254.66\n",
       "2010-11-25 07:40:00     -2.11    978.08       1254.57\n",
       "2010-11-25 07:50:00     -2.09    978.07       1254.44\n",
       "2010-11-25 08:00:00     -1.95    978.08       1253.78\n",
       "2010-11-25 08:10:00     -1.85    978.08       1253.31\n",
       "2010-11-25 08:20:00     -1.78    978.10       1253.02\n",
       "2010-11-25 08:30:00     -1.70    978.19       1252.76\n",
       "2010-11-25 08:40:00     -1.54    978.19       1252.00\n",
       "2010-11-25 08:50:00     -1.43    978.19       1251.52\n",
       "2010-11-25 09:00:00     -1.32    978.19       1251.02\n",
       "2010-11-25 09:10:00     -1.21    978.19       1250.52\n",
       "2010-11-25 09:20:00     -1.22    978.19       1250.59\n",
       "2010-11-25 09:30:00     -1.18    978.17       1250.37\n",
       "2010-11-25 09:40:00     -0.90    978.09       1248.92\n",
       "2010-11-25 09:50:00     -0.77    978.08       1248.30\n",
       "2010-11-25 10:00:00     -0.73    978.07       1248.10\n",
       "2010-11-25 10:10:00     -0.62    978.04       1247.54\n",
       "2010-11-25 10:20:00     -0.30    977.96       1245.92\n",
       "2010-11-25 10:30:00      0.50    977.94       1242.25\n",
       "2010-11-25 10:40:00      0.95    977.88       1240.10\n",
       "2010-11-25 10:50:00      1.10    977.82       1239.34\n",
       "2010-11-25 11:00:00      1.13    977.71       1239.05\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preload=0\n",
    "lmodel1 = TimeSeriesLSTM(history=720, nfeats=3, target_ahead=72, UNITS1=32, UNITS2=0, npreds=1, skip=6, verbose=0)\n",
    "lmodel1.model()\n",
    "\n",
    "if (preload == 1):\n",
    "    lmodel1.load()\n",
    "    lmodel1.prepSet(prep)\n",
    "elif(preload == 0):\n",
    "    prep=lmodel1.prepare(dfn2,0,50000)\n",
    "    #lmodel1.save()\n",
    "    \n",
    "predictPlot_(0, 100, title=\"default weight\", **vars(lmodel1) );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    display.clear_output(wait=True)\n",
    "    plt.clf()\n",
    "    predictPlot_(305000, 400, title=f\"{i}\", **vars(lmodel1) )\n",
    "    plt.show()\n",
    "    display.display(plt.gcf())\n",
    "    lmodel1.fit(1,1)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_step_model = load_model(\"single_step_model.hd5\")\n",
    "#predictPlot_(0, 100, 720,1,lmodel1.df, lmodel1, 72, lmodel1.scaler, 0, \"single_step_model\");\n",
    "\n",
    "#xp,yp,*_=predictPlot_(0, 100, 720, npreds=1, DFN=lmodel1.df, model=single_step_model, \n",
    "#                          target_ahead=72, scaler=None, target=0, skip=72, title=\"single_step_model\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictPlot_(305000, 400, title=f\"{i}\", **vars(lmodel1) );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# MultiVariate Multiple Steps Predictions\n",
    "\n",
    "This uses multiple features dfn2 has 3 features we will use to train; We will also predict temperature far ahead in the future say 12 hours ahead.\n",
    "\n",
    "We will use 5 days of historical data with 3 features. Since temperature dont change often we down sample the entire data set to hours instead of 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preload=0\n",
    "opt=tf.keras.optimizers.RMSprop(clipvalue=1.0)\n",
    "lmodel2 = TimeSeriesLSTM(history=720, nfeats=3, target_ahead=72,UNITS1=32,UNITS2=16,npreds=12, skip=6, OPTIMIZER=opt)\n",
    "lmodel2.model()\n",
    "\n",
    "if (preload == 1):\n",
    "    lmodel1.load()\n",
    "    lmodel1.prepSet(prep)\n",
    "elif(preload == 0):\n",
    "    prep=lmodel2.prepare(dfn2,0,50000)\n",
    "    #lmodel1.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yh=predictPlot_(0, 100, **vars(lmodel2) );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    display.clear_output(wait=True)\n",
    "    plt.clf()\n",
    "    predictPlot_(0, 100, **vars(lmodel2) )\n",
    "    plt.show()\n",
    "    display.display(plt.gcf())\n",
    "    lmodel2.fit(1,0)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=lmodel2.model\n",
    "m.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "time_series.ipynb",
   "private_outputs": true,
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
