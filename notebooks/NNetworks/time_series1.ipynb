{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<textarea rows=5 id=nav_head_content style=\"width:100%;display:none;\">\n",
       "<style>\n",
       "a.bh,  a.bh:visited, a.bh:link, a.bh:active {\n",
       "  ttext-decoration: none; \n",
       "  color: black;\n",
       "  font-family: 'Roboto','Heebo',Arial,sans-serif;\n",
       "  font-size: 3em\n",
       "}\n",
       "</style>\n",
       "<div id='HTMLTopBar' style=\"    \n",
       "    z-index: 50;\n",
       "    align-items: stretch;\n",
       "    width:100%\">\n",
       "    <div  style=\"\n",
       "        text-color: black;\n",
       "        background-color: #fefefe;\n",
       "        bborder-bottom: 1px dotted gray;\n",
       "        padding-left: 2px;\n",
       "        box-shadow: 5px 1px #ccc;\n",
       "        height: 40px; left: 0; \n",
       "        padding: 14px;\n",
       "        \"\n",
       "    >\n",
       "    <a class=bh1 href=\"#\" onclick=\"$('#maintoolbar').toggle();\">X</a>\n",
       "</div>\n",
       "</textarea>\n",
       "\n",
       "<script>\n",
       "if ($('#nav_head').length < 1) {\n",
       "    $('#notebook-container').prepend('<div id=\"nav_head\" style=\"width:100%;\">.</div>')\n",
       "    console.log(\"Added a div\")\n",
       "} else{\n",
       "    console.log(\"Already Added\")    \n",
       "}\n",
       "\n",
       "$('#nav_head').html($('#nav_head_content').val())\n",
       "\n",
       "$('.nbp-app-bar').toggle()\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url('https://fonts.googleapis.com/css2?family=Roboto&display=swap');\n",
       "</style>\n",
       "<style>\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Roboto&display=swap\" \n",
       "                            rel=\"stylesheet\">\n",
       "\n",
       "body  p ol li {\n",
       "    font-family: \"Roboto\",  \"Lucida Grande\", \"Lucida Sans Unicode\";\n",
       "    font-size: 14px;\n",
       "    background: #fff\n",
       "}\n",
       "\n",
       "h1, h2, h3{\n",
       "    font-family: 'Roboto', sans-serif;\n",
       "}\n",
       "div#notebook_panel div#notebook{\n",
       "    background: #ffffff\n",
       "}\n",
       "div#notebook-container{\n",
       "    box-shadow: 0px;\n",
       "    padding: 0px;\n",
       "    border-left: .05em dotted gray;\n",
       "    -webkit-box-shadow: 0px;\n",
       "    box-shadow: none;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".container { width: 100% !important; }\n",
       "    div.cell{\n",
       "        width:100%;\n",
       "        margin-left:0%;\n",
       "        margin-right:auto;\n",
       "}\n",
       ".CodeMirror {\n",
       "    font-family: monospace;\n",
       "}\n",
       "div.input_area {\n",
       "    border: 0px;\n",
       "}\n",
       "div.cell.selected{\n",
       "  border: '0px';\n",
       "}\n",
       ".cell.selected{\n",
       "  border: '0px';\n",
       "}\n",
       "div#notebook{\n",
       "    padding-top: 0px;\n",
       "}\n",
       "div.prompt_container {\n",
       "    display: block; \n",
       "    background: #f7f7f7;\n",
       "}\n",
       "div.prompt{\n",
       "    min-width:0px;\n",
       "    display: grid;\n",
       "}\n",
       "div.cell{\n",
       "    padding-bottom: 5px;\n",
       "    padding-left: 0px;\n",
       "}\n",
       "\n",
       "a.bh,  a.bh:visited, a.bh:link, a.bh:active {\n",
       "  text-decoration: none; \n",
       "  color:white;\n",
       "  font-family: 'Roboto','Heebo',Arial,sans-serif;\n",
       "  font-size:1em\n",
       "}\n",
       "a.bh:hover {\n",
       "  color: #ffccdd;\n",
       "}\n",
       "\n",
       "a.bh1,  a.bh1:visited, a.bh1:link, a.bh1:active {\n",
       "  text-decoration: none; \n",
       "  color: rgba(0, 0, 0, 0.87);\n",
       "  font-family: 'Roboto','Heebo',Arial,sans-serif;\n",
       "  padding-right: 30px;\n",
       "  font-size:1.1em\n",
       "}\n",
       "a.bh1:hover {\n",
       "  color: rgba(0, 0, 0, 0.57);\n",
       "}\n",
       "    \n",
       "#toc-wrapper {\n",
       "   font-family: 'Roboto','Heebo',Arial,sans-serif;\n",
       "    border: 0px dotted gray;\n",
       "    padding: 10px;\n",
       "    line-height: 1.8em;\n",
       "}    \n",
       "</style>\n",
       "<script>\n",
       "l=\"https://www.ancient-symbols.com/images/wp-image-library/fullsize/infinity.jpg\"\n",
       "l=\"imgs/logo.png\"\n",
       "l=\"\"\n",
       "$('#ipython_notebook').html(`<img src=\"${l}\">`)\n",
       "\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "import colabexts\n",
    "from colabexts.jcommon import *\n",
    "\n",
    "jpath=os.path.dirname(colabexts.__file__)\n",
    "jcom = f'{jpath}/jcommon.ipynb'\n",
    "%run $jcom\n",
    "\n",
    "import os, datetime\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (16, 5)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "print(tf.__version__)\n",
    "\n",
    "#dfn.plot(subplots=True)\n",
    "#trainPercent = .7\n",
    "tf.random.set_seed(13)\n",
    "#--------------------------------------------------------------------------------\n",
    "def get_data(dataset, target, start, end, history, target_size, skip=1,oneStep=False):\n",
    "    data   = []\n",
    "    labels = []\n",
    "\n",
    "    start = start + history\n",
    "    if end is None:\n",
    "        end = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start, end):\n",
    "        #print(f\"++ {i}  {start} {end_index} \\r\", end=\"\")\n",
    "        indices = range(i-history, i, skip)\n",
    "        \n",
    "        dt = np.reshape(dataset[indices], ( -1, dataset.shape[-1]))\n",
    "        data.append(dt)\n",
    "\n",
    "        if oneStep:\n",
    "            labels.append(target[i+target_size])\n",
    "        else:\n",
    "            labels.append(target[i:i+target_size])\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# target: column to predict\n",
    "# history      : how long of history to look\n",
    "# target_ahead : how much in the future \"target\" is predicted\n",
    "#      =>confusing!! if values right next to it is predicted, it is =0\n",
    "#      if say, you lke to predict 5 time steps aheads then it is 5\n",
    "#\n",
    "# single_oneStepstep : # predictions\n",
    "# pct         : percentage split or a number of samples\n",
    "def get_split(df, history,target=None, pct=0.7, \n",
    "                  target_ahead=0, skip=1, oneStep=True):\n",
    "\n",
    "    TRAIN_SPLIT = int(len(df) * trainPercent) if (pct < 1) else pct\n",
    "    target = target if target else df.columns[0]\n",
    "    \n",
    "    print(f\"Training_split: {TRAIN_SPLIT}, target: {target}\")\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    dfs = scaler.fit(df[:TRAIN_SPLIT])\n",
    "    dfs.mean_, dfs.scale_\n",
    "    dfns = (df-dfs.mean_)/dfs.scale_ \n",
    "    \n",
    "    ds = dfns.values\n",
    "    xtrn, ytrn = get_data(ds, dfns[target].values, 0, TRAIN_SPLIT,\n",
    "                        history, target_ahead,skip,True)\n",
    "    xval, yval = get_data(ds, dfns[target].values, TRAIN_SPLIT, None,\n",
    "                        history, target_ahead,skip,True)\n",
    "    \n",
    "    return scaler, dfns, xtrn, ytrn, xval, yval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>rho (g/m**3)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:10:00</th>\n",
       "      <td>-8.02</td>\n",
       "      <td>996.52</td>\n",
       "      <td>1307.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:20:00</th>\n",
       "      <td>-8.41</td>\n",
       "      <td>996.57</td>\n",
       "      <td>1309.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:30:00</th>\n",
       "      <td>-8.51</td>\n",
       "      <td>996.53</td>\n",
       "      <td>1310.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31 23:40:00</th>\n",
       "      <td>-3.16</td>\n",
       "      <td>999.82</td>\n",
       "      <td>1288.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31 23:50:00</th>\n",
       "      <td>-4.23</td>\n",
       "      <td>999.81</td>\n",
       "      <td>1293.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>-4.82</td>\n",
       "      <td>999.82</td>\n",
       "      <td>1296.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420551 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     T (degC)  p (mbar)  rho (g/m**3)\n",
       "Date Time                                            \n",
       "2009-01-01 00:10:00     -8.02    996.52       1307.75\n",
       "2009-01-01 00:20:00     -8.41    996.57       1309.80\n",
       "2009-01-01 00:30:00     -8.51    996.53       1310.24\n",
       "...                       ...       ...           ...\n",
       "2016-12-31 23:40:00     -3.16    999.82       1288.39\n",
       "2016-12-31 23:50:00     -4.23    999.81       1293.56\n",
       "2017-01-01 00:00:00     -4.82    999.82       1296.38\n",
       "\n",
       "[420551 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Data\n",
    "#del dfn1\n",
    "if ( \"dfn1\" not in globals()):\n",
    "    csv_path = 'jena_climate_2009_2016.csv.zip'\n",
    "    df = pd.read_csv(csv_path, nrows=1000000)\n",
    "    df['Date Time'] = pd.to_datetime( df['Date Time'] )\n",
    "\n",
    "    dfn1= df[['T (degC)']].copy()\n",
    "    dfn1.index = df['Date Time']\n",
    "\n",
    "    dfn2= df[['T (degC)', 'p (mbar)', 'rho (g/m**3)']].copy()\n",
    "    dfn2.index = df['Date Time']\n",
    "\n",
    "    dfn = dfn2\n",
    "    dfn\n",
    "    \n",
    "dfn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[  -8.02,  996.52, 1307.75],\n",
       "         [  -8.41,  996.57, 1309.8 ],\n",
       "         [  -8.51,  996.53, 1310.24],\n",
       "         [  -8.31,  996.51, 1309.19],\n",
       "         [  -8.27,  996.51, 1309.  ]],\n",
       " \n",
       "        [[  -8.41,  996.57, 1309.8 ],\n",
       "         [  -8.51,  996.53, 1310.24],\n",
       "         [  -8.31,  996.51, 1309.19],\n",
       "         [  -8.27,  996.51, 1309.  ],\n",
       "         [  -8.05,  996.5 , 1307.86]],\n",
       " \n",
       "        [[  -8.51,  996.53, 1310.24],\n",
       "         [  -8.31,  996.51, 1309.19],\n",
       "         [  -8.27,  996.51, 1309.  ],\n",
       "         [  -8.05,  996.5 , 1307.86],\n",
       "         [  -7.62,  996.5 , 1305.68]]]),\n",
       " array([[-8.05, -7.62, -7.62, -7.91],\n",
       "        [-7.62, -7.62, -7.91, -8.43],\n",
       "        [-7.62, -7.91, -8.43, -8.76]]),\n",
       " (95, 5, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar=dfn2.columns[0]\n",
    "#get_data(dataset, target, start, end, history, target_size, skip=1,oneStep=False):\n",
    "X, y = get_data(dfn2.values, dfn2[tar].values, 0, 100, 5, 4, skip=1,oneStep=False)\n",
    "X[0:3], y[0:3], X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['T (degC)', 'p (mbar)', 'rho (g/m**3)'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 8,\n",
      "batch --size=2\n",
      "[[[10, 15], [20, 25]]] => [[30]]\n",
      "[[[20, 25], [30, 35]]] => [[40]]\n",
      "[[[30, 35], [40, 45]]] => [[50]]\n",
      "[[[40, 45], [50, 55]]] => [[60]]\n",
      "[[[50, 55], [60, 65]]] => [[70]]\n",
      "[[[60, 65], [70, 75]]] => [[80]]\n",
      "[[[70, 75], [80, 85]]] => [[90]]\n",
      "[[[80, 85], [90, 95]]] => [[100]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "# define dataset\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95, 105])\n",
    "# reshape series\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2))\n",
    "#print(dataset)\n",
    "generator2 = TimeseriesGenerator(dataset, in_seq1, length=2, batch_size=1)\n",
    "print(f'Samples: {len(generator2)},')\n",
    "print('batch --size=2')    \n",
    "for i in range(len(generator2)):\n",
    "    x, y = generator2[i]\n",
    "    xx = [[list(c) for c in cc] for cc in x]\n",
    "    yy = [list(c) for c in y]\n",
    "    print(f'{xx} => {yy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[10, 15],\n",
       "         [20, 25],\n",
       "         [30, 35],\n",
       "         [40, 45],\n",
       "         [50, 55]],\n",
       " \n",
       "        [[20, 25],\n",
       "         [30, 35],\n",
       "         [40, 45],\n",
       "         [50, 55],\n",
       "         [60, 65]],\n",
       " \n",
       "        [[30, 35],\n",
       "         [40, 45],\n",
       "         [50, 55],\n",
       "         [60, 65],\n",
       "         [70, 75]]]),\n",
       " array([array([[60],\n",
       "        [70],\n",
       "        [80],\n",
       "        [90]]),\n",
       "        array([[ 70],\n",
       "        [ 80],\n",
       "        [ 90],\n",
       "        [100]]),\n",
       "        array([[ 80],\n",
       "        [ 90],\n",
       "        [100]])], dtype=object),\n",
       " (5, 5, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get_data(dataset, target, start, end, history, target_size, skip=1,oneStep=False):\n",
    "X, y = get_data(dataset, in_seq1, 0, 10, 5, 4, skip=1,oneStep=False)\n",
    "X[0:3], y[0:3], X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0]\n",
      "  [2]\n",
      "  [4]\n",
      "  [6]\n",
      "  [8]]\n",
      "\n",
      " [[1]\n",
      "  [3]\n",
      "  [5]\n",
      "  [7]\n",
      "  [9]]] => [[10]\n",
      " [11]]\n",
      "\n",
      "\n",
      "For Nice printing\n",
      "[[[0], [2], [4], [6], [8]], [[1], [3], [5], [7], [9]]] => [[10], [11]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import numpy as np\n",
    "data = array([[i] for i in range(50)])\n",
    "targets = array([[i] for i in range(50)])\n",
    "data_gen = TimeseriesGenerator(data, targets,\n",
    "                               length=10, sampling_rate=2,\n",
    "                               batch_size=2)\n",
    "'''assert len(data_gen) == 20\n",
    "batch_0 = data_gen[0]\n",
    "x, y = batch_0\n",
    "assert np.array_equal(x,\n",
    "                      np.array([[[0], [2], [4], [6], [8]],\n",
    "                                [[1], [3], [5], [7], [9]]]))\n",
    "assert np.array_equal(y,\n",
    "                      np.array([[10], [11]]))\n",
    "\n",
    "data.shape'''\n",
    "\n",
    "for i in range(len(data_gen)):\n",
    "    x, y = data_gen[i]\n",
    "    print(f'{x} => {y}\\n')\n",
    "    \n",
    "    #Just for printing purposes only\n",
    "    xx = [[list(c) for c in cc] for cc in x]\n",
    "    yy = [list(c) for c in y]\n",
    "    print(f'\\nFor Nice printing\\n{xx} => {yy}')\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesLSTM:\n",
    "    '''\n",
    "    df    : data frame\n",
    "    UNITS1: # units in layer1 of LSTM\n",
    "    UNITS2: # units in layer2 of LSTM, 0 if one layer\n",
    "    nfeats: number of features\n",
    "    target_ahead and npreds = how far ahead to predict, single or multiple\n",
    "    '''\n",
    "    def __init__(self, history, nfeats, target_ahead = 0, skip=1,\n",
    "                 UNITS1=32, UNITS2=0, npreds=1, verbose=1,\n",
    "                 OPTIMIZER = 'adam', model_file=\"temp.hd5\"\n",
    "                ):\n",
    "        self.UNITS1       = UNITS1 or 32\n",
    "        self.UNITS2       = UNITS2 or 0\n",
    "        self.history      = history\n",
    "        self.npreds       = npreds\n",
    "        self.target_ahead = target_ahead\n",
    "        self.model_file   = model_file\n",
    "        self.skip         = skip\n",
    "        \n",
    "        self.nfeats       = nfeats\n",
    "        self.BATCH_SIZE   = 256\n",
    "        self.BUFFER_SIZE  = 10000\n",
    "        self.EPOCHS       = 20\n",
    "        self.LOSS         = \"mae\"\n",
    "        #self.OPTIMIZER    = tf.keras.optimizers.RMSprop(clipvalue=1.0)\n",
    "        self.OPTIMIZER    = OPTIMIZER\n",
    "        self.EVAL_INTERVAL= 200\n",
    "        self.VAL_STEPS    = 50\n",
    "        self.V            = verbose\n",
    "\n",
    "    ''' This just builds a model '''\n",
    "    def model(self):\n",
    "        m = tf.keras.models.Sequential()\n",
    "        \n",
    "        hist =int(self.history/self.skip)\n",
    "        m.add(LSTM(self.UNITS1, return_sequences= (self.npreds >1),\n",
    "                        input_shape=(hist, self.nfeats) ))\n",
    "        if(self.UNITS2):\n",
    "            m.add(tf.keras.layers.LSTM(self.UNITS2, activation='relu'))\n",
    "        m.add(tf.keras.layers.Dense(self.npreds))\n",
    "        m.compile(optimizer = self.OPTIMIZER, loss=self.LOSS)\n",
    "        \n",
    "        self.model = m\n",
    "        return m\n",
    "    \n",
    "    def prepare(self, dfn,target=None, pct=0.7):\n",
    "        self.DFN    = dfn;\n",
    "        self.target = target\n",
    "        \n",
    "        ret = get_split( dfn, self.history, target, pct,\n",
    "                        self.target_ahead, self.skip,\n",
    "                        oneStep = (self.npreds <= 1) )\n",
    "\n",
    "        scaler, df, xtrn, ytrn, xval, yval = ret\n",
    "        \n",
    "        trn = tf.data.Dataset.from_tensor_slices((xtrn, ytrn))\n",
    "        trn = trn.cache().shuffle(self.BUFFER_SIZE).batch(\n",
    "                self.BATCH_SIZE).repeat()\n",
    "\n",
    "        val = tf.data.Dataset.from_tensor_slices((xval, yval))\n",
    "        val = val.batch(self.BATCH_SIZE).repeat()\n",
    "\n",
    "        self.scaler, self.df, self.xtrn, self.ytrn,  \\\n",
    "                                self.xval, self.yval = ret\n",
    "        self.trn, self.val = trn, val\n",
    "        \n",
    "        return self.DFN, self.skip, self.target, ret, trn, val\n",
    " \n",
    "    def prepSet(self,prepped):\n",
    "        self.DFN, self.skip, self.target, ret, self.trn, self.val = prepped\n",
    "        self.scaler, self.df, self.xtrn, self.ytrn,  \\\n",
    "                                self.xval, self.yval = ret\n",
    "    \n",
    "    def fit(self, epochs=None, verbose=None):\n",
    "        \n",
    "        epochs = epochs  or self.EPOCHS\n",
    "        verbose= verbose or self.V\n",
    "        \n",
    "        trn, val = self.trn, self.val\n",
    "        self.model.fit(trn, verbose=verbose, epochs=epochs,\n",
    "                steps_per_epoch = self.EVAL_INTERVAL,\n",
    "                validation_data = val, validation_steps=self.VAL_STEPS,\n",
    "                      callbacks=None)\n",
    "        \n",
    "    def save(self):\n",
    "        self.model.save(self.model_file)\n",
    "\n",
    "    def load(self):\n",
    "        self.model = load_model(self.model_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictPlot_(start    , howmany, history      , npreds  ,\n",
    "                 DFN      , model   , target_ahead , scaler, target, skip=1, title=\"\",**kwargs):\n",
    "    \n",
    "    ds1   = DFN[start:start+howmany+history+target_ahead].values\n",
    "\n",
    "    xp, yp = get_data(ds1, ds1[:, target], 0, None,\n",
    "                         history, target_ahead, skip, npreds<=1)\n",
    "\n",
    "    if (scaler is not None):\n",
    "        for i,x  in enumerate(xp):\n",
    "            xp[i] = scaler.transform(xp[i])\n",
    "\n",
    "    yh1= model.predict(xp)\n",
    "    yh = yh1\n",
    "    if (scaler is not None):\n",
    "        #yh = scaler.inverse_transform(yh1)\n",
    "        yh = yh1 * scaler.scale_[target]\n",
    "        yh = yh  + scaler.mean_[target]\n",
    "\n",
    "    #print(xtrn[0], ytrn[0],dfn.iloc[0])\n",
    "    target = dfn.columns[0]\n",
    "\n",
    "\n",
    "    plt.plot(yp[:,0], marker=\".\", label = \"y\")\n",
    "    plt.plot(yh, marker=\"x\", label = \"$\\hat{y}$\")\n",
    "    for i in range (yh.shape[0]):\n",
    "        pass\n",
    "        #plt.plot(yh[:,i], marker=\"x\", label= f\"predicted: {i}\")\n",
    "    \n",
    "    idx= DFN.index[start+history+target_ahead : start+howmany+history+target_ahead]\n",
    "    intv = max(1, int(len(idx)/10) )\n",
    "    plt.xticks(range(0,len(yh),10), idx, rotation=45)\n",
    "    \n",
    "    assert len(idx) == len(yp), \"Hmmm Something calculations dont jibe!!!\"\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.grid(b=\"on\")\n",
    "    plt.legend()\n",
    "    #pr = lstm.predict(xtrn[1].reshape(1,xtrn[0\n",
    "    return xp,yp, yh, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\"dfn1\" not in globals()):\n",
    "    csv_path = 'jena_climate_2009_2016.csv.zip'\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['Date Time'] = pd.to_datetime( df['Date Time'] )\n",
    "\n",
    "    dfn1= df[['T (degC)']].copy()\n",
    "    dfn1.index = df['Date Time']\n",
    "\n",
    "    dfn2= df[['T (degC)', 'p (mbar)', 'rho (g/m**3)']].copy()\n",
    "    dfn2.index = df['Date Time']\n",
    "\n",
    "    dfn = dfn2\n",
    "    dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T (degC)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date Time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:10:00</th>\n",
       "      <td>-8.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:20:00</th>\n",
       "      <td>-8.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:30:00</th>\n",
       "      <td>-8.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31 23:40:00</th>\n",
       "      <td>-3.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31 23:50:00</th>\n",
       "      <td>-4.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>-4.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420551 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     T (degC)\n",
       "Date Time                    \n",
       "2009-01-01 00:10:00     -8.02\n",
       "2009-01-01 00:20:00     -8.41\n",
       "2009-01-01 00:30:00     -8.51\n",
       "...                       ...\n",
       "2016-12-31 23:40:00     -3.16\n",
       "2016-12-31 23:50:00     -4.23\n",
       "2017-01-01 00:00:00     -4.82\n",
       "\n",
       "[420551 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_split: 300000, target: T (degC)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: temp.hd5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: temp.hd5/assets\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-39a5da150374>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mlmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mpredictPlot_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Before Train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-e7fd2c3f5094>\u001b[0m in \u001b[0;36mpredictPlot_\u001b[0;34m(start, howmany, history, npreds, DFN, model, target_ahead, scaler, target, skip, title, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"$\\hat{y}$\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0myh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "mpl.rcParams['figure.figsize'] = (16, 5)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "lmodel = TimeSeriesLSTM(history=20, nfeats=1, target_ahead=0, skip=1,\n",
    "                 UNITS1=32, UNITS2=0, npreds=1, verbose=0)\n",
    "\n",
    "lmodel.model()\n",
    "preload=0\n",
    "if (preload):\n",
    "    lmodel.load()\n",
    "    lmodel.prepSet(prep)\n",
    "else:\n",
    "    prep=lmodel.prepare(dfn1,0, 300000)\n",
    "    lmodel.save()\n",
    "    \n",
    "predictPlot_(0, 100, title=\"Before Train\", **vars(lmodel) );\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = datetime.datetime.now()\n",
    "for i in range(10):\n",
    "    display.clear_output(wait=True)\n",
    "    plt.clf()\n",
    "    predictPlot_(0, 100, title=f\"{i}\", **vars(lmodel) )\n",
    "    plt.show()\n",
    "    display.display(plt.gcf())\n",
    "    lmodel.fit(1,1)\n",
    "t2 = datetime.datetime.now()\n",
    "print(f\"++ time : {t2-t1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_lstm_model = load_model(\"simple_lstm_model.hd5\")\n",
    "predictPlot_(0, 100, 20,1,lmodel.DFN, simple_lstm_model, 0, lmodel.scaler, 0, 1,\"Simple LSTM Model\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# MultiVariate Single Step Predictions\n",
    "\n",
    "This uses multiple features dfn2 has 3 features we will use to train;\n",
    "We will also predict temperature far ahead in the future say 12 hours ahead.\n",
    "\n",
    "We will use 5 days of historical data with 3 features. Since temperature dont change often we down sample \n",
    "the entire data set to hours instead of 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preload=0\n",
    "lmodel1 = TimeSeriesLSTM(history=720, nfeats=3, target_ahead=72, UNITS1=32, UNITS2=0, npreds=1, skip=6, verbose=0)\n",
    "lmodel1.model()\n",
    "\n",
    "if (preload == 1):\n",
    "    lmodel1.load()\n",
    "    lmodel1.prepSet(prep)\n",
    "elif(preload == 0):\n",
    "    prep=lmodel1.prepare(dfn2,0,50000)\n",
    "    #lmodel1.save()\n",
    "    \n",
    "predictPlot_(0, 100, title=\"default weight\", **vars(lmodel1) );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    display.clear_output(wait=True)\n",
    "    plt.clf()\n",
    "    predictPlot_(305000, 400, title=f\"{i}\", **vars(lmodel1) )\n",
    "    plt.show()\n",
    "    display.display(plt.gcf())\n",
    "    lmodel1.fit(1,1)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_step_model = load_model(\"single_step_model.hd5\")\n",
    "#predictPlot_(0, 100, 720,1,lmodel1.df, lmodel1, 72, lmodel1.scaler, 0, \"single_step_model\");\n",
    "\n",
    "#xp,yp,*_=predictPlot_(0, 100, 720, npreds=1, DFN=lmodel1.df, model=single_step_model, \n",
    "#                          target_ahead=72, scaler=None, target=0, skip=72, title=\"single_step_model\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictPlot_(305000, 400, title=f\"{i}\", **vars(lmodel1) );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# MultiVariate Multiple Steps Predictions\n",
    "\n",
    "This uses multiple features dfn2 has 3 features we will use to train; We will also predict temperature far ahead in the future say 12 hours ahead.\n",
    "\n",
    "We will use 5 days of historical data with 3 features. Since temperature dont change often we down sample the entire data set to hours instead of 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preload=0\n",
    "opt=tf.keras.optimizers.RMSprop(clipvalue=1.0)\n",
    "lmodel2 = TimeSeriesLSTM(history=720, nfeats=3, target_ahead=72,UNITS1=32,UNITS2=16,npreds=12, skip=6, OPTIMIZER=opt)\n",
    "lmodel2.model()\n",
    "\n",
    "if (preload == 1):\n",
    "    lmodel1.load()\n",
    "    lmodel1.prepSet(prep)\n",
    "elif(preload == 0):\n",
    "    prep=lmodel2.prepare(dfn2,0,50000)\n",
    "    #lmodel1.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yh=predictPlot_(0, 100, **vars(lmodel2) );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    display.clear_output(wait=True)\n",
    "    plt.clf()\n",
    "    predictPlot_(0, 100, **vars(lmodel2) )\n",
    "    plt.show()\n",
    "    display.display(plt.gcf())\n",
    "    lmodel2.fit(1,0)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=lmodel2.model\n",
    "m.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "time_series.ipynb",
   "private_outputs": true,
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
