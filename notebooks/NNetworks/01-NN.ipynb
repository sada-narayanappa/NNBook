{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<textarea rows=5 id=nav_head_content style=\"width:100%;display:none;\">\n",
       "<style>\n",
       "a.bh,  a.bh:visited, a.bh:link, a.bh:active {\n",
       "  ttext-decoration: none; \n",
       "  color: black;\n",
       "  font-family: 'Roboto','Heebo',Arial,sans-serif;\n",
       "  font-size: 3em\n",
       "}\n",
       "</style>\n",
       "<!--\n",
       "<div id='HTMLTopBar' style=\"    \n",
       "    z-index: 50;\n",
       "    align-items: stretch;\n",
       "    width:100%\">\n",
       "    <div  style=\"\n",
       "        text-color: black;\n",
       "        background-color: #fefefe;\n",
       "        bborder-bottom: 1px dotted gray;\n",
       "        padding-left: 2px;\n",
       "        box-shadow: 5px 1px #ccc;\n",
       "        height: 40px; left: 0; \n",
       "        padding: 14px;\n",
       "        \"\n",
       "    >\n",
       "    <a class=bh1 href=\"#\" onclick=\"$('#maintoolbar').toggle();\">X</a>\n",
       "</div>\n",
       "-->\n",
       "</textarea>\n",
       "\n",
       "<script>\n",
       "if ($('#nav_head').length < 1) {\n",
       "    $('#notebook-container').prepend('<div id=\"nav_head\" style=\"width:100%;\">.</div>')\n",
       "    console.log(\"Added a div\")\n",
       "} else{\n",
       "    console.log(\"Already Added\")    \n",
       "}\n",
       "\n",
       "$('#nav_head').html($('#nav_head_content').val())\n",
       "\n",
       "$('.nbp-app-bar').toggle()\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url('https://fonts.googleapis.com/css2?family=Roboto&display=swap');\n",
       "</style>\n",
       "<style>\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Roboto&display=swap\" rel=\"stylesheet\">\n",
       "\n",
       "body  p ol li {\n",
       "    font-family: \"Roboto\",  \"Lucida Grande\", \"Lucida Sans Unicode\";\n",
       "    font-size: 14px;\n",
       "    background: #fff\n",
       "}\n",
       "\n",
       "h1, h2, h3{\n",
       "    font-family: 'Roboto', sans-serif;\n",
       "}\n",
       "div#notebook_panel div#notebook{\n",
       "    background: #ffffff\n",
       "}\n",
       "div#notebook-container{\n",
       "    box-shadow: 0px;\n",
       "    padding: 0px;\n",
       "    border-left: .05em dotted gray;\n",
       "    -webkit-box-shadow: 0px;\n",
       "    box-shadow: none;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".container { width: 100% !important; }\n",
       "    div.cell{\n",
       "        width:100%;\n",
       "        margin-left:0%;\n",
       "        margin-right:auto;\n",
       "}\n",
       ".CodeMirror {\n",
       "    font-family: monospace;\n",
       "}\n",
       "div.input_area {\n",
       "    border: 0px;\n",
       "}\n",
       "div.cell.selected{\n",
       "  border: '0px';\n",
       "}\n",
       ".cell.selected{\n",
       "  border: '0px';\n",
       "}\n",
       "div#notebook{\n",
       "    padding-top: 0px;\n",
       "}\n",
       "div.prompt_container {\n",
       "    display: block; \n",
       "    background: #f7f7f7;\n",
       "}\n",
       "div.prompt{\n",
       "    min-width:0px;\n",
       "    display: grid;\n",
       "}\n",
       "div.cell{\n",
       "    padding-bottom: 5px;\n",
       "    padding-left: 0px;\n",
       "}\n",
       "\n",
       "a.bh,  a.bh:visited, a.bh:link, a.bh:active {\n",
       "  text-decoration: none; \n",
       "  color:white;\n",
       "  font-family: 'Roboto','Heebo',Arial,sans-serif;\n",
       "  font-size:1em\n",
       "}\n",
       "a.bh:hover {\n",
       "  color: #ffccdd;\n",
       "}\n",
       "\n",
       "a.bh1,  a.bh1:visited, a.bh1:link, a.bh1:active {\n",
       "  text-decoration: none; \n",
       "  color: rgba(0, 0, 0, 0.87);\n",
       "  font-family: 'Roboto','Heebo',Arial,sans-serif;\n",
       "  padding-right: 30px;\n",
       "  font-size:1.1em\n",
       "}\n",
       "a.bh1:hover {\n",
       "  color: rgba(0, 0, 0, 0.57);\n",
       "}\n",
       "    \n",
       "#toc-wrapper {\n",
       "   font-family: 'Roboto','Heebo',Arial,sans-serif;\n",
       "    border: 0px dotted gray;\n",
       "    padding: 10px;\n",
       "    line-height: 1.8em;\n",
       "}    \n",
       "</style>\n",
       "<script>\n",
       "l=\"https://www.ancient-symbols.com/images/wp-image-library/fullsize/infinity.jpg\"\n",
       "l=\"imgs/logo.png\"\n",
       "l=\"\"\n",
       "$('#ipython_notebook').html(`<img src=\"${l}\">`)\n",
       "\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "import colabexts\n",
    "from colabexts.jcommon import *\n",
    "\n",
    "jpath=os.path.dirname(colabexts.__file__)\n",
    "jcom = f'{jpath}/jcommon.ipynb'\n",
    "%run $jcom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivative of a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.004001, 3.9960010000000006, 0.007999999999999119, 3.9999999999995595)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your own way of computing the derivative of a function\n",
    "\n",
    "def fn(x):\n",
    "    return x * x;\n",
    "\n",
    "e  = 0.001\n",
    "x  = 2\n",
    "f1 = fn(x-e)\n",
    "f2 = fn(x+e)\n",
    "f2, f1, f2-f1, (f2-f1)/(2*e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Differentition and Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.8.0', '2.8.0')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "tf.__version__, keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Computations\n",
    "\n",
    "To differentiate automatically, tf needs to remember what operations happen in what order during the forward pass. Then, during the backward pass, tf traverses this list of operations in reverse order to compute gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "derivative of 'x' w.r.t. 'y' @ 3 is 6.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x**2\n",
    "\n",
    "dy_dx = tape.gradient(y, x)\n",
    "print( f\"derivative of 'x' w.r.t. 'y' @ 3 is {dy_dx}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientTape works on any length of computation and on any tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.2250001, shape=(), dtype=float32)\n",
      "\n",
      "Loss: 1.2250001430511475 \n",
      "Y: \n",
      "[[1.4000001  1.4000001 ]\n",
      " [0.70000005 0.70000005]]\n",
      "Shape of w  (2, 3)  ; b.shape = (1, 2) \n",
      "Shape of w' (2, 3)\n",
      "W-tanspose: \n",
      "==========\n",
      "[[0.1 0.2 0.3]\n",
      " [0.1 0.  0.2]]\n",
      "\n",
      "Derivative:\n",
      "==========\n",
      "[[1.4000001  2.8000002  4.2000003 ]\n",
      " [0.70000005 1.4000001  2.1000001 ]]\n",
      "[[1.0500001 1.0500001]]\n",
      "\n",
      "ERROR: A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "#w = tf.Variable(tf.random.normal((3, 2)), name='w')\n",
    "w = tf.Variable([[.1, .2, .3], [.1,0.,.2]])\n",
    "w = tf.Variable(w, name='w')\n",
    "b = tf.Variable(tf.zeros((1,2) , dtype=tf.float32), name='b')\n",
    "x = [[1.], [2.], [3.]]\n",
    "\n",
    "with tf.GradientTape(persistent=False) as tape:\n",
    "    y = w @ x  + b\n",
    "    loss = tf.reduce_mean(y**2)\n",
    "    print( loss)\n",
    "[dl_dw, dl_db] = tape.gradient(loss, [w, b])\n",
    "  \n",
    "print(f'''\n",
    "Loss: {loss} \n",
    "Y: \n",
    "{y}\n",
    "Shape of w  {w.shape}  ; b.shape = {b.shape} \n",
    "Shape of w' {dl_dw.shape}\n",
    "W-tanspose: \n",
    "==========\n",
    "{w.numpy()}\n",
    "\n",
    "Derivative:\n",
    "==========\n",
    "{dl_dw.numpy()}\n",
    "{dl_db.numpy()}\n",
    "''' )\n",
    "\n",
    "# persistent is se to False - therefoire, calling gradient gives error\n",
    "\n",
    "try:\n",
    "    [dl_dw, dl_db] = tape.gradient(loss, [w, b])\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: {e}\")\n",
    "\n",
    "#if you make persistent as True make sure to delete te tape to reduce memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More on Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model Dense and Counting # of parameters\n",
    "\n",
    "Notice here, input size is 3; and,\n",
    "first layer has 2 nodes\n",
    "similarly, second layer has 2 nodes\n",
    "\n",
    "The weight matrix must be 2x3 + 2 for the bias = 8 parameters\n",
    "For the 2nd layer, The weight matrix must be 2x2 + 2 for the bias = 6 parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_49 (Dense)            (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 2)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14\n",
      "Trainable params: 14\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[array([[-0.43570435,  0.7112912 ],\n",
      "       [ 0.68243146, -0.49273908],\n",
      "       [-0.21341771,  0.23050165]], dtype=float32), array([0., 0.], dtype=float32)]\n",
      "[array([[0.7621423 , 0.6043643 ],\n",
      "       [0.8276237 , 0.96114886]], dtype=float32), array([0., 0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# A simple MLP\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Dense(2, activation='relu', input_shape=[3] ) )\n",
    "model.add(Dense(2, activation='relu' ) )\n",
    "model.summary()\n",
    "print(model.layers[0].get_weights())\n",
    "print(model.layers[1].get_weights())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Network with one node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass and Backard pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Weights: (2, 1) [[0.5]] [0.]\n",
      "Yhat:  [[0.5]] must be equal to = 0.5\n",
      "Lets do backward pass - see notes\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 90.2500\n",
      "Loss: is:  90.25  must be equal to = (10-0.5)^2 = 90.25\n",
      "Layer Weights: (2, 1) [[2.4]] [1.9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%writefile /tmp/t.py\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "tf.__version__, keras.__version__\n",
    "\n",
    "# A Simple Network with One Node weights\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Dense(1, activation='relu', input_dim=1, name=\"w1\"))\n",
    "lr =0.1\n",
    "opt=tf.keras.optimizers.SGD(learning_rate=lr, momentum=0, nesterov=False)\n",
    "model.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "# ~~~ Set custom weights\n",
    "wts, bias =( np.array([[0.5]]), np.array([0]) )\n",
    "model.layers[0].set_weights((wts, bias) )\n",
    "\n",
    "# ~~~ Print the weights\n",
    "wts11=model.layers[0].get_weights()\n",
    "print('Layer Weights:', np.array(wts11).shape, wts11[0], wts11[1] )\n",
    "\n",
    "data=np.array([[1]]).reshape(1,-1)\n",
    "y = np.array([10])\n",
    "yhat = model.predict(data, verbose=0)\n",
    "print(\"Yhat: \" , yhat, \"must be equal to = 0.5\")\n",
    "\n",
    "print (\"Lets do backward pass - see notes\")\n",
    "f = model.fit(data, y, epochs=1, verbose=1)\n",
    "\n",
    "print(\"Loss: is: \" , f.history['loss'][-1], \" must be equal to = (10-0.5)^2 = 90.25\")\n",
    "\n",
    "# ~~~ Print the weights - see lecture on youtube\n",
    "wts11=model.layers[0].get_weights()\n",
    "print('Layer Weights:', np.array(wts11).shape, wts11[0], wts11[1] )\n",
    "\n",
    "'''#--- Do one pass through NN\n",
    "\n",
    "print('Call Predict on untrained model'  )\n",
    "\n",
    "f = model.fit(data, y, epochs=1000, verbose=0)\n",
    "for i in range(10):\n",
    "    wts11= model.layers[0].get_weights()\n",
    "    f = model.fit(data, y, epochs=1000, verbose=0)\n",
    "    wts12= model.layers[0].get_weights()\n",
    "    yhat = model.predict(data, verbose=0)\n",
    "    print(f\\' ''Fit {i}: {data} y: {y}  y^: {yhat}; Loss: {f.history['loss'][-1]}\n",
    "weights:   {wts11[0][0], wts11[1][0] }; \n",
    "after fit: {wts12[0][0], wts12[1][0] }\\n\\n' '' \n",
    "         \n",
    "         )\n",
    "    if ( isclose(wts11[0][0], wts12[0][0], abs_tol=1e-9)):\n",
    "        print(f\"*** CHANGING LR: {model.optimizer.learning_rate.numpy()}\")\n",
    "        K.set_value(model.optimizer.learning_rate, model.optimizer.learning_rate*4)\n",
    "    \n",
    "print(f\"#--- Weights after {i} pass\");\n",
    "wts1=model.layers[0].get_weights()\n",
    "op=model.layers[0].output\n",
    "\n",
    "yhat = model.predict(data, verbose=0)\n",
    "wts11= np.array(model.layers[0].get_weights())\n",
    "print('Weights:' , wts11.shape, wts11,  \"Output: \", yhat )\n",
    "'''\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.45]]), array([[0.5]]), array([-0.95]))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = (10-0.5)**2\n",
    "dl_dw= np.sqrt(loss) * -data.flatten() * lr\n",
    "w1 = wts - dl_dw\n",
    "w1, wts, dl_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.499999009676685"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f1(x, y= 10, b =0):\n",
    "    return (y - (0.5 * x +b)) **2\n",
    "\n",
    "e = 1e-9\n",
    "x = 1\n",
    "(f1(x+e) - f1(x-e))/(2*e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9000000000000001"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-2 * np.sqrt(f1(x)) *lr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.9])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * np.sqrt(loss) * -data.flatten() * lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Little more extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights(1): (1, 1) [[0.5]]\n",
      "Layer Weights: (1, 1) (1,) [[0.5]] [0.]\n",
      "Call Predict on untrained model\n",
      "Before Fit:  [[0.5]]\n",
      "Fit 0: [[1]] y: [10]  y^: [[0.]]; Loss: 100.0\n",
      "weights:   (array([-37.5], dtype=float32), -38.0); \n",
      "after fit: (array([-37.5], dtype=float32), -38.0)\n",
      "\n",
      "\n",
      "*** CHANGING LR: 1\n",
      "Fit 1: [[1]] y: [10]  y^: [[0.]]; Loss: 100.0\n",
      "weights:   (array([-37.5], dtype=float32), -38.0); \n",
      "after fit: (array([-37.5], dtype=float32), -38.0)\n",
      "\n",
      "\n",
      "*** CHANGING LR: 4\n",
      "Fit 2: [[1]] y: [10]  y^: [[0.]]; Loss: 100.0\n",
      "weights:   (array([-37.5], dtype=float32), -38.0); \n",
      "after fit: (array([-37.5], dtype=float32), -38.0)\n",
      "\n",
      "\n",
      "*** CHANGING LR: 16\n",
      "Fit 3: [[1]] y: [10]  y^: [[0.]]; Loss: 100.0\n",
      "weights:   (array([-37.5], dtype=float32), -38.0); \n",
      "after fit: (array([-37.5], dtype=float32), -38.0)\n",
      "\n",
      "\n",
      "*** CHANGING LR: 64\n",
      "Fit 4: [[1]] y: [10]  y^: [[0.]]; Loss: 100.0\n",
      "weights:   (array([-37.5], dtype=float32), -38.0); \n",
      "after fit: (array([-37.5], dtype=float32), -38.0)\n",
      "\n",
      "\n",
      "*** CHANGING LR: 256\n",
      "Fit 5: [[1]] y: [10]  y^: [[0.]]; Loss: 100.0\n",
      "weights:   (array([-37.5], dtype=float32), -38.0); \n",
      "after fit: (array([-37.5], dtype=float32), -38.0)\n",
      "\n",
      "\n",
      "*** CHANGING LR: 1024\n",
      "Fit 6: [[1]] y: [10]  y^: [[0.]]; Loss: 100.0\n",
      "weights:   (array([-37.5], dtype=float32), -38.0); \n",
      "after fit: (array([-37.5], dtype=float32), -38.0)\n",
      "\n",
      "\n",
      "*** CHANGING LR: 4096\n",
      "Fit 7: [[1]] y: [10]  y^: [[0.]]; Loss: 100.0\n",
      "weights:   (array([-37.5], dtype=float32), -38.0); \n",
      "after fit: (array([-37.5], dtype=float32), -38.0)\n",
      "\n",
      "\n",
      "*** CHANGING LR: 16384\n",
      "Fit 8: [[1]] y: [10]  y^: [[0.]]; Loss: 100.0\n",
      "weights:   (array([-37.5], dtype=float32), -38.0); \n",
      "after fit: (array([-37.5], dtype=float32), -38.0)\n",
      "\n",
      "\n",
      "*** CHANGING LR: 65536\n",
      "Fit 9: [[1]] y: [10]  y^: [[0.]]; Loss: 100.0\n",
      "weights:   (array([-37.5], dtype=float32), -38.0); \n",
      "after fit: (array([-37.5], dtype=float32), -38.0)\n",
      "\n",
      "\n",
      "*** CHANGING LR: 262144\n",
      "#--- Weights after 9 pass\n",
      "Weights: (2, 1) [[-37.5]\n",
      " [-38.0]] Output:  [[0.]]\n"
     ]
    }
   ],
   "source": [
    "# A Simple Network with One Node weights\n",
    "from keras import backend as K\n",
    "from math import isclose\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Dense(1, activation='relu', input_dim=1))\n",
    "opt=tf.keras.optimizers.SGD(learning_rate=1, momentum=0.0, nesterov=False)\n",
    "#model.compile(optimizer=opt, loss='binary_crossentropy')\n",
    "model.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "# ~~~ Set custom weights\n",
    "wts1=( np.array([[0.5]]),  np.array([0]) )\n",
    "print('Weights(1):' , wts1[0].shape, wts1[0] )\n",
    "model.layers[0].set_weights(wts1)\n",
    "wts11=model.layers[0].get_weights()\n",
    "print('Layer Weights:' , wts11[0].shape, wts11[1].shape, wts11[0], wts11[1] )\n",
    "\n",
    "#--- Do one pass through NN\n",
    "data=np.array([[1]]).reshape(1,-1)\n",
    "y = np.array([10])\n",
    "\n",
    "print('Call Predict on untrained model'  )\n",
    "yhat = model.predict(data, verbose=0)\n",
    "print(\"Before Fit: \" , yhat)\n",
    "\n",
    "f = model.fit(data, y, epochs=1000, verbose=0)\n",
    "for i in range(10):\n",
    "    wts11= model.layers[0].get_weights()\n",
    "    f = model.fit(data, y, epochs=1000, verbose=0)\n",
    "    wts12= model.layers[0].get_weights()\n",
    "    yhat = model.predict(data, verbose=0)\n",
    "    print(f'''Fit {i}: {data} y: {y}  y^: {yhat}; Loss: {f.history['loss'][-1]}\n",
    "weights:   {wts11[0][0], wts11[1][0] }; \n",
    "after fit: {wts12[0][0], wts12[1][0] }\\n\\n''' \n",
    "         \n",
    "         )\n",
    "    if ( isclose(wts11[0][0], wts12[0][0], abs_tol=1e-9)):\n",
    "        print(f\"*** CHANGING LR: {model.optimizer.learning_rate.numpy()}\")\n",
    "        K.set_value(model.optimizer.learning_rate, model.optimizer.learning_rate*4)\n",
    "    \n",
    "print(f\"#--- Weights after {i} pass\");\n",
    "wts1=model.layers[0].get_weights()\n",
    "op=model.layers[0].output\n",
    "\n",
    "yhat = model.predict(data, verbose=0)\n",
    "wts11= np.array(model.layers[0].get_weights())\n",
    "print('Weights:' , wts11.shape, wts11,  \"Output: \", yhat )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NW with predefined weights and one pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights(0): (2, 2) (2,) \n",
      " [[0.5 0.1]\n",
      " [0.1 0.5]] [0 0]\n",
      "Weights: (2, 2) (2,) [[0.5 0.1]\n",
      " [0.1 0.5]] [0. 0.]\n",
      "Weights(1): (2, 1) (1,) \n",
      " [[0.5]\n",
      " [0.5]] [0]\n",
      "Weights: (2, 1) (1,) [[0.5]\n",
      " [0.5]] [0.]\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 88.3600\n",
      "#--- Weights after one pass\n",
      "Weights: (2, 2) (2,) [[0.594 0.194]\n",
      " [0.194 0.594]] [0.094 0.094]\n",
      "Weights: (2, 1) (1,) [[0.6128]\n",
      " [0.6128]] [0.188]\n"
     ]
    }
   ],
   "source": [
    "# A Simple Network with predefined weights\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2, activation='relu', input_dim=2))\n",
    "model.add(Dense(1))\n",
    "opt=tf.keras.optimizers.SGD(learning_rate=0.5, momentum=0.0, nesterov=False)\n",
    "#model.compile(optimizer=opt, loss='binary_crossentropy')\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "# ~~~ Set custom weights\n",
    "wts0=( np.array([[0.5, 0.1], [0.1, 0.5]]),  np.array([0,0]) )\n",
    "print('Weights(0):' , wts0[0].shape, wts0[1].shape, \"\\n\", wts0[0], wts0[1] )\n",
    "\n",
    "model.layers[0].set_weights(wts0)\n",
    "wts01=model.layers[0].get_weights()\n",
    "print('Weights:' , wts01[0].shape, wts01[1].shape, wts01[0], wts01[1] )\n",
    "\n",
    "wts1=( np.array([[0.5], [0.5]]),  np.array([0]) )\n",
    "print('Weights(1):' , wts1[0].shape, wts1[1].shape, \"\\n\", wts1[0], wts1[1] )\n",
    "model.layers[1].set_weights(wts1)\n",
    "wts11=model.layers[1].get_weights()\n",
    "print('Weights:' , wts11[0].shape, wts11[1].shape, wts11[0], wts11[1] )\n",
    "\n",
    "#--- Do one pass through NN\n",
    "data=np.array([[1,1]])\n",
    "y =np.array([10])\n",
    "f=model.fit(data, y, epochs=1, verbose=1)\n",
    "\n",
    "print(\"#--- Weights after one pass\");\n",
    "wts1=model.layers[0].get_weights()\n",
    "print('Weights:' , wts1[0].shape, wts1[1].shape, wts1[0], wts1[1] )\n",
    "wts11=model.layers[1].get_weights()\n",
    "print('Weights:' , wts11[0].shape, wts11[1].shape, wts11[0], wts11[1] )\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
