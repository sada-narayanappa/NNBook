{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM using TimeGenerator \n",
    "\n",
    "A more meaningful and complete example is given below that can be used as a black-box. Here we give multivariate, single step prediction with various look ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import os, datetime\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython import display\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (16, 5)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "tf.random.set_seed(13)\n",
    "pd.options.display.max_rows = 8\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>rho (g/m**3)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:10:00</th>\n",
       "      <td>-8.02</td>\n",
       "      <td>996.52</td>\n",
       "      <td>1307.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:20:00</th>\n",
       "      <td>-8.41</td>\n",
       "      <td>996.57</td>\n",
       "      <td>1309.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:30:00</th>\n",
       "      <td>-8.51</td>\n",
       "      <td>996.53</td>\n",
       "      <td>1310.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:40:00</th>\n",
       "      <td>-8.31</td>\n",
       "      <td>996.51</td>\n",
       "      <td>1309.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 10:30:00</th>\n",
       "      <td>0.50</td>\n",
       "      <td>977.94</td>\n",
       "      <td>1242.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 10:40:00</th>\n",
       "      <td>0.95</td>\n",
       "      <td>977.88</td>\n",
       "      <td>1240.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 10:50:00</th>\n",
       "      <td>1.10</td>\n",
       "      <td>977.82</td>\n",
       "      <td>1239.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25 11:00:00</th>\n",
       "      <td>1.13</td>\n",
       "      <td>977.71</td>\n",
       "      <td>1239.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     T (degC)  p (mbar)  rho (g/m**3)\n",
       "Date Time                                            \n",
       "2009-01-01 00:10:00     -8.02    996.52       1307.75\n",
       "2009-01-01 00:20:00     -8.41    996.57       1309.80\n",
       "2009-01-01 00:30:00     -8.51    996.53       1310.24\n",
       "2009-01-01 00:40:00     -8.31    996.51       1309.19\n",
       "...                       ...       ...           ...\n",
       "2010-11-25 10:30:00      0.50    977.94       1242.25\n",
       "2010-11-25 10:40:00      0.95    977.88       1240.10\n",
       "2010-11-25 10:50:00      1.10    977.82       1239.34\n",
       "2010-11-25 11:00:00      1.13    977.71       1239.05\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Data\n",
    "#del dfn1\n",
    "if ( \"dfn1\" not in globals()):\n",
    "    csv_path = 'jena_climate_2009_2016.csv.zip'\n",
    "    df = pd.read_csv(csv_path, nrows=100000)\n",
    "    df['Date Time'] = pd.to_datetime( df['Date Time'] )\n",
    "\n",
    "    dfn1= df[['T (degC)']].copy()\n",
    "    dfn1.index = df['Date Time']\n",
    "\n",
    "    dfn2= df[['T (degC)', 'p (mbar)', 'rho (g/m**3)']].copy()\n",
    "    dfn2.index = df['Date Time']\n",
    "\n",
    "    dfn = dfn2\n",
    "    dfn\n",
    "    \n",
    "dfn2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Review the data carefully. It has 100k rows, readings taken for every 10 minutes; we chose 3 features (it can be one). We want to look back 720 readings back (in a day we have 24 * 6 = 144 readings, we sample every 6th, reading, therefore, we must have 120 time-steps x 3 features) and predict the temperature one hour ahead i.e. 10 readings ahead) \n",
    "\n",
    "Notice we carefully chose one hour ahead prediction because, it aligns well with sampling_rate of 6.\n",
    "If we wanted to predict two hours ahead, we cannot use sampling_rate, because it affects both X and y. \n",
    "In this case we must adjust labels correctly.\n",
    "\n",
    "Similarly if we wanted multistep, then we must prepare y appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This just builds a model \n",
    "Optimizeers\n",
    "opt1 = tf.keras.optimizers.RMSprop(clipvalue=1.0)\n",
    " \n",
    " inshape = input shape => #time_steps x #features\n",
    "'''\n",
    "import keras\n",
    "\n",
    "def lstmmodel(inps, inshape, units2=None, nsteps=1, opt=\"adam\", loss=\"mse\", bi=False, dropout=None):\n",
    "    s= inshape\n",
    "    print(locals())\n",
    "    print(f\"Creating LSTM: inuts= {inps} time-steps: {s[0]}, features: {s[1]} #out: {nsteps}\")\n",
    "    m = keras.models.Sequential()\n",
    "\n",
    "    if (bi):\n",
    "        m.add(keras.layers.Bidirectional(\n",
    "            keras.layers.LSTM(inps, return_sequences= (units2 is not None), input_shape=s) ) )\n",
    "    else:\n",
    "        m.add(keras.layers.LSTM(inps, return_sequences= (units2 is not None), input_shape=s) )\n",
    "    \n",
    "    if(units2 is not None): #Lets just keep it simple for 2 layers only\n",
    "        m.add(keras.layers.LSTM(units2, activation='relu'))\n",
    "    if (dropout is not None):\n",
    "        m.add( keras.layers.Dropout(dropout) )\n",
    "    m.add(keras.layers.Dense(nsteps))\n",
    "    m.compile(optimizer = opt, loss= loss)\n",
    "    return m\n",
    " \n",
    "def makestep(a, start, steps=5):\n",
    "    o= []\n",
    "    for i in range(steps):\n",
    "        a1 = a[start+i:-steps+i+1 or None]\n",
    "        o.append(a1)\n",
    "    \n",
    "    return np.hstack([o]).T\n",
    "\n",
    "def Plot_(y, h, x=None, title=None,**kwargs):\n",
    "    #x = x if x is not None else range(len(y))\n",
    "    plt.plot(y[:,0], marker=\".\", label = \"y\")\n",
    "\n",
    "    if ( len(h.shape) <= 1):\n",
    "        h = h.reshape((len(h), 1))\n",
    "    for i in range(h.shape[-1]):\n",
    "        uy=h[i:,i]\n",
    "        plt.plot(range(i, len(uy)+i), uy, marker=\"x\",  label = f\"$h_{i}$\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.grid(b=\"on\")\n",
    "    plt.legend()\n",
    "    return y1, h1;\n",
    "\n",
    "def modelEqual(m1, m2):\n",
    "    ok = len(m1.layers) ==  len(m2.layers)\n",
    "    if (not ok):\n",
    "        return ok\n",
    "\n",
    "    for l1, l2 in zip(m1.layers, m.layers):\n",
    "        c1, c2 = l1.get_config(), l2.get_config()\n",
    "        tn = c1['name'] \n",
    "        c1['name'] = c2['name'] \n",
    "        ok = c1 == c2 \n",
    "        c1['name'] = tn\n",
    "        if (not ok):\n",
    "            break;\n",
    "    return ok\n",
    "\n",
    "class NNmodel:\n",
    "    def __init__(self, tsParams, model, file=None,  nsteps=1, load=True):\n",
    "        defp =  { \n",
    "                    \"length\":         20,\n",
    "                    \"batch_size\":     256,\n",
    "                    \"stride\":         1,\n",
    "                    \"sampling_rate\" : 1\n",
    "                }\n",
    "        self.model = m\n",
    "        self.tsParam(tsParams or defp)\n",
    "        \n",
    "        if( file is not None):\n",
    "            self.model_file=file;\n",
    "            #Load the file and other parameters \n",
    "            if (load and os.path.exists(file)):\n",
    "                m1=self.load()\n",
    "                if modelEqual(m,m1) or m is None:\n",
    "                    m.set_weights(m1.get_weights()) \n",
    "                    print(f\"Using the loaded model {file}!!\")\n",
    "                else:\n",
    "                    print(\"Models are different, ignoring model loaded from file\")\n",
    "        \n",
    "        self.nsteps= nsteps # nstep predictions\n",
    "    \n",
    "    def tsParam(self, tsParams = None):\n",
    "        if (tsParams is not None):\n",
    "            self.tsParams = tsParams;\n",
    "            self.setvals(tsParams)\n",
    "        return self.tsParams;\n",
    "    \n",
    "    def setvals(self, d: dict):\n",
    "        for k, v in d.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "    def save(self, file = None):\n",
    "        model_file = file or self.model_file\n",
    "        self.model.save(model_file)\n",
    "\n",
    "    def load(self, file = None):\n",
    "        model_file = file or self.model_file\n",
    "        m = load_model(model_file)\n",
    "        return m\n",
    "\n",
    "    def dump(self):\n",
    "        vr = vars(nnmodel)\n",
    "        for k,v in vr.items():\n",
    "            if type(v) == pd.core.frame.DataFrame:\n",
    "                print(f'{k}: shape:{v.shape}')\n",
    "            else:\n",
    "                print(f'{k}, {type(v)}: {v}')\n",
    "                \n",
    "    # First, do preprocessing which consists of:\n",
    "    # 1. Remove time correlated variables\n",
    "    # 2. Add a time cycle if it makes sense, Suppose a event occurs based on time, then we must have that cycle\n",
    "    # 3. Normalize the data\n",
    "\n",
    "    # *NOTE* we scale only on the training data - *NOT* on the entire dataset\n",
    "    #\n",
    "    def prepare(self,dfn2, pct=0.8):\n",
    "        df = dfn2.copy()\n",
    "\n",
    "        trni = int(len(df) * pct) if (pct < 1) else pct\n",
    "\n",
    "        print(f\"#Training samples: {trni}\")\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        dfs = scaler.fit(df[:trni])\n",
    "        dfs.mean_, dfs.scale_\n",
    "        dfns = (df-dfs.mean_)/dfs.scale_\n",
    "\n",
    "        self.df, self.trn, self.val, self.scaler = dfns, dfns[:trni], dfns[trni:], scaler\n",
    "        \n",
    "        return self.df, self.trn, self.val, self.scaler \n",
    "    \n",
    "    #def createModel(self, inps, inshape, units2=None, nstep=1, opt=\"adam\", loss=\"mse\" ):\n",
    "    #    self.model = lstmmodel(inps, inshape, units2=units2, nstep=nstep, opt=\"adam\", loss=\"mse\" )\n",
    "\n",
    "    def tsg(self, data: np.ndarray,  scale=False, batch_size=None,lables=None, lableIndex=0):\n",
    "\n",
    "        lables = lables if lables is not None else data[:,lableIndex]\n",
    "        \n",
    "        if (scale):\n",
    "            data = (data-self.scaler.mean_)/self.scaler.scale_\n",
    "\n",
    "        tsParams = self.tsParams\n",
    "        if (batch_size is not None and batch_size != tsParams['batch_size']):\n",
    "            tsParams = self.tsParams.copy()\n",
    "            tsParams['batch_size'] = batch_size;\n",
    "          \n",
    "        print(tsParams)\n",
    "        \n",
    "        lables = makestep(lables, 0, self.nsteps)\n",
    "        #print(f'==> {lables.shape}, {nsteps}')\n",
    "        data   = data[:-self.nsteps+1 or None]\n",
    "        \n",
    "        tsg    = TimeseriesGenerator(data, lables, **tsParams )\n",
    "        return tsg\n",
    "        \n",
    "    def tsgfit(self, lables=None, lableIndex=0):\n",
    "        self.trng    = self.tsg( self.trn.values, lables=lables, lableIndex=lableIndex )\n",
    "        self.valg    = self.tsg( self.val.values, lables=lables, lableIndex=lableIndex  )\n",
    "\n",
    "        return self.trng, self.valg\n",
    "\n",
    "    def fit(self,epochs=1, trn=None, val=None):\n",
    "        if not hasattr( self, \"trng\"):\n",
    "            self.tsgfit()\n",
    "            \n",
    "        if (trn is None or val is None):\n",
    "            trn,val = self.trng, self.valg\n",
    "            \n",
    "        for i in range(epochs):\n",
    "            self.model.fit(trn, verbose=1, epochs=1, validation_data=val, steps_per_epoch=200, \n",
    "                          validation_steps=50, workers=4, use_multiprocessing=True)\n",
    "             \n",
    "    def predict(self, df, start=0, howmany=100, lableIndex=0, scalein=False, scaleout=True, title=\"\"):\n",
    "        data=df\n",
    "        scaler = self.scaler\n",
    "        model = self.model\n",
    "\n",
    "        if (type(df) == pd.DataFrame):\n",
    "            data = df.values\n",
    "\n",
    "        if (scalein):\n",
    "            data = (data-scaler.mean_)/scaler.scale_\n",
    "\n",
    "        data   = df[start:].values\n",
    "        labels = data[:, lableIndex]\n",
    "        g=self.tsg(data, batch_size=howmany, lableIndex=0)\n",
    "        x, y = g[0]\n",
    "        h = model.predict(x)\n",
    "\n",
    "        h1, y1 = h,y\n",
    "        if (scaleout):\n",
    "            h1 = h * scaler.scale_[lableIndex]\n",
    "            h1 = h1  + scaler.mean_[lableIndex]\n",
    "\n",
    "            y1 = y * scaler.scale_[lableIndex]\n",
    "            y1 = y1  + scaler.mean_[lableIndex]\n",
    "\n",
    "        return y1, h1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# All steps reusing the functions \n",
    "# Step 1. Read Data here\n",
    "#Lets review the generator output\n",
    "tsParams={ \n",
    "    \"length\":         20,\n",
    "    \"batch_size\":     256,\n",
    "    \"stride\":         1,\n",
    "    \"sampling_rate\" : 1\n",
    "}\n",
    "\n",
    "m = lstmmodel(32, (20,1), units2=None, nsteps=1, opt=\"adam\", loss=\"mse\" )\n",
    "nnmodel1 = NNmodel(tsParams=tsParams, model=m, file=\"m1.h5\")\n",
    "nnmodel1.prepare(dfn1, pct=80000)\n",
    "\n",
    "y1, h1 = nnmodel1.predict(nnmodel1.df,0, 100)\n",
    "o= Plot_(y1, h1, title=\"Initial Weights Predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "for i in range(epochs):\n",
    "    plt.clf()  \n",
    "    y1, h1 = nnmodel1.predict(nnmodel1.df,0, 100)\n",
    "    Plot_( y1, h1, title=f\"{i}\")\n",
    "    plt.show()\n",
    "    nnmodel1.fit()\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    #IPython.display.display(plt.gcf())\n",
    "\n",
    "nnmodel1.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Rate and Stride\n",
    "\n",
    "Just inspect what are the values set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sanity Check to make sure everything is aligned\n",
    "tsParams={ \n",
    "    \"length\":         720,\n",
    "    \"batch_size\":     256,\n",
    "    \"stride\":         1,\n",
    "    \"sampling_rate\" : 6\n",
    "}\n",
    "data   = dfn2.values\n",
    "labels = data[:,0]\n",
    "g = TimeseriesGenerator(data, labels, **tsParams )\n",
    "\n",
    "#Lets review the generator output\n",
    "x, y = g[0]    \n",
    "print(f'{x.shape}, {y.shape} {y[0]}')\n",
    "print(f'X: \\n{x[0][-3:]} <= should match every 6th entry\\n Also: \\n{y[0]} <= 720th entry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check to visually check if X and y correctly aligned\n",
    "# Whenever you see \"<=\" mark, it is aligned at sampling rate of 6\n",
    "\n",
    "dfn3= dfn2.copy()\n",
    "dfn3['idx'] = [i if i % 6 != 0 else f'<={i}' for i in range(len(dfn3))]\n",
    "display(dfn3[700:724])\n",
    "del dfn3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets build a model with multiple features\n",
    "\n",
    "# All steps reusing the functions \n",
    "# Step 1. Read Data here\n",
    "#Lets review the generator output\n",
    "tsParams={ \n",
    "    \"length\":         720,\n",
    "    \"batch_size\":     256,\n",
    "    \"stride\":         1,\n",
    "    \"sampling_rate\" : 6\n",
    "}\n",
    "\n",
    "\n",
    "m = lstmmodel(32, (120,3), units2=None, nsteps=1, opt=\"adam\", loss=\"mse\" )\n",
    "nnmodel1f = NNmodel(tsParams=tsParams, model=m, file=\"m3.h5\")\n",
    "nnmodel1f.prepare(dfn2, pct=80000)\n",
    "\n",
    "y1, h1 = nnmodel1f.predict(nnmodel1f.df,0, 100)\n",
    "o=Plot_(y1, h1, title=\"Initial Weights Predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs= 4\n",
    "for i in range(epochs):\n",
    "    plt.clf()  \n",
    "    y1, h1 = nnmodel1f.predict(nnmodel1f.df,0, 100)\n",
    "    Plot_( y1, h1, title=f\"{i}\")\n",
    "    plt.show()\n",
    "    nnmodel1f.fit()\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    #IPython.display.display(plt.gcf())\n",
    "nnmodel1f.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the performance with one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets try sampling rate with one feature\n",
    "\n",
    "# All steps reusing the functions \n",
    "# Step 1. Read Data here\n",
    "#Lets review the generator output\n",
    "tsParams={ \n",
    "    \"length\":         720,\n",
    "    \"batch_size\":     256,\n",
    "    \"stride\":         1,\n",
    "    \"sampling_rate\" : 6\n",
    "}\n",
    "\n",
    "m = lstmmodel(32, (120,1), units2=None, nsteps=1, opt=\"adam\", loss=\"mse\" )\n",
    "nnmodel1s = NNmodel(tsParams=tsParams, model=m, file=\"m3-1.h5\")\n",
    "nnmodel1s.prepare(dfn1, pct=80000)\n",
    "\n",
    "y1, h1 = nnmodel1s.predict(nnmodel1s.df,0, 100)\n",
    "o=Plot_(y1, h1, title=\"Initial Weights Predictions: sample every 6th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5\n",
    "for i in range(epochs):\n",
    "    plt.clf()  \n",
    "    y1, h1 = nnmodel1s.predict(nnmodel1s.df,0, 100)\n",
    "    Plot_( y1, h1, title=f\"{i}\")\n",
    "    plt.show()\n",
    "    nnmodel1s.fit()\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    #IPython.display.display(plt.gcf())\n",
    "\n",
    "nnmodel1s.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s,h = 95000, 100\n",
    "y1, h1 = nnmodel1s.predict(nnmodel1s.df,s,h)\n",
    "Plot_( y1, h1, title=f\"{s}-{h}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# MultiVariate Multiple Step Predictions\n",
    "\n",
    "TimeseriesGenerator dont have mechanisms to generate multistep out, we need to prepare the data set as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example Uage of makesteps\n",
    "a=list(range(10))\n",
    "k=makestep(a, 5, 3)\n",
    "a, k.shape, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets build a model with multiple features\n",
    "\n",
    "# All steps reusing the functions \n",
    "# Step 1. Read Data here\n",
    "#Lets review the generator output\n",
    "tsParams={ \n",
    "    \"length\":         720,\n",
    "    \"batch_size\":     256,\n",
    "    \"stride\":         1,\n",
    "    \"sampling_rate\" : 6\n",
    "}\n",
    "\n",
    "nsteps = 5 # 5 predictions\n",
    "\n",
    "m = lstmmodel(32, (120,3), units2=32, nsteps=nsteps, opt=\"adam\", loss=\"mse\" )\n",
    "nnmodel1mf = NNmodel(tsParams=tsParams, model=m, nsteps=nsteps, file=\"m3-step-5.h5\")\n",
    "nnmodel1mf.prepare(dfn2, pct=80000)\n",
    "\n",
    "y1,h1 = nnmodel1mf.predict(nnmodel1mf.df,0, 100, scaleout=True)\n",
    "#o=Plot_(y1, h1, title=\"Initial Weights Predictions-multistep\")\n",
    "o=Plot_(y1, h1, title=\"Initial Weights Predictions: sample every 6th\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=4\n",
    "for i in range(epochs):\n",
    "    plt.clf()  \n",
    "    y1,h1 = nnmodel1mf.predict(nnmodel1mf.df,0, 100)\n",
    "    Plot_( y1, h1, title=f\"{i}\")\n",
    "    plt.show()\n",
    "    nnmodel1mf.fit()\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    #IPython.display.display(plt.gcf())\n",
    "\n",
    "nnmodel1mf.save();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=nnmodel1mf.model\n",
    "\n",
    "keras.engine.sequential.Sequential.summary(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.get_input_shape_at(0), m.get_output_shape_at(0)\n",
    "for i in range(len(m.layers)):\n",
    "    l = m.layers[i]\n",
    "    s = l.get_input_shape_at(0)\n",
    "    o = l.get_output_shape_at(0)\n",
    "    print(f'{i}=> inp shape: {str(s):15}, out shape: {o}')\n",
    "\n",
    "l.get_output_shape_at(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=m.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(l.get_weights())):\n",
    "    print(l.get_weights()[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 *128 + 32 *128 + 128"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "time_series.ipynb",
   "private_outputs": true,
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
