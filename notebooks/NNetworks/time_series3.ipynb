{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM using TimeGenerator \n",
    "\n",
    "A more meaningful and complete example is given below that can be used as a black-box. Here we give multivariate, single step prediction with various look ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<textarea rows=5 id=nav_head_content style=\"width:100%;display:none;\">\n",
       "<style>\n",
       "a.bh,  a.bh:visited, a.bh:link, a.bh:active {\n",
       "  ttext-decoration: none; \n",
       "  color: black;\n",
       "  font-family: 'Roboto','Heebo',Arial,sans-serif;\n",
       "  font-size: 3em\n",
       "}\n",
       "</style>\n",
       "<div id='HTMLTopBar' style=\"    \n",
       "    z-index: 50;\n",
       "    align-items: stretch;\n",
       "    width:100%\">\n",
       "    <div  style=\"\n",
       "        text-color: black;\n",
       "        background-color: #fefefe;\n",
       "        bborder-bottom: 1px dotted gray;\n",
       "        padding-left: 2px;\n",
       "        box-shadow: 5px 1px #ccc;\n",
       "        height: 40px; left: 0; \n",
       "        padding: 14px;\n",
       "        \"\n",
       "    >\n",
       "    <a class=bh1 href=\"#\" onclick=\"$('#maintoolbar').toggle();\">X</a>\n",
       "</div>\n",
       "</textarea>\n",
       "\n",
       "<script>\n",
       "if ($('#nav_head').length < 1) {\n",
       "    $('#notebook-container').prepend('<div id=\"nav_head\" style=\"width:100%;\">.</div>')\n",
       "    console.log(\"Added a div\")\n",
       "} else{\n",
       "    console.log(\"Already Added\")    \n",
       "}\n",
       "\n",
       "$('#nav_head').html($('#nav_head_content').val())\n",
       "\n",
       "$('.nbp-app-bar').toggle()\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url('https://fonts.googleapis.com/css2?family=Roboto&display=swap');\n",
       "</style>\n",
       "<style>\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Roboto&display=swap\" \n",
       "                            rel=\"stylesheet\">\n",
       "\n",
       "body  p ol li {\n",
       "    font-family: \"Roboto\",  \"Lucida Grande\", \"Lucida Sans Unicode\";\n",
       "    font-size: 14px;\n",
       "    background: #fff\n",
       "}\n",
       "\n",
       "h1, h2, h3{\n",
       "    font-family: 'Roboto', sans-serif;\n",
       "}\n",
       "div#notebook_panel div#notebook{\n",
       "    background: #ffffff\n",
       "}\n",
       "div#notebook-container{\n",
       "    box-shadow: 0px;\n",
       "    padding: 0px;\n",
       "    border-left: .05em dotted gray;\n",
       "    -webkit-box-shadow: 0px;\n",
       "    box-shadow: none;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".container { width: 100% !important; }\n",
       "    div.cell{\n",
       "        width:100%;\n",
       "        margin-left:0%;\n",
       "        margin-right:auto;\n",
       "}\n",
       ".CodeMirror {\n",
       "    font-family: monospace;\n",
       "}\n",
       "div.input_area {\n",
       "    border: 0px;\n",
       "}\n",
       "div.cell.selected{\n",
       "  border: '0px';\n",
       "}\n",
       ".cell.selected{\n",
       "  border: '0px';\n",
       "}\n",
       "div#notebook{\n",
       "    padding-top: 0px;\n",
       "}\n",
       "div.prompt_container {\n",
       "    display: block; \n",
       "    background: #f7f7f7;\n",
       "}\n",
       "div.prompt{\n",
       "    min-width:0px;\n",
       "    display: grid;\n",
       "}\n",
       "div.cell{\n",
       "    padding-bottom: 5px;\n",
       "    padding-left: 0px;\n",
       "}\n",
       "\n",
       "a.bh,  a.bh:visited, a.bh:link, a.bh:active {\n",
       "  text-decoration: none; \n",
       "  color:white;\n",
       "  font-family: 'Roboto','Heebo',Arial,sans-serif;\n",
       "  font-size:1em\n",
       "}\n",
       "a.bh:hover {\n",
       "  color: #ffccdd;\n",
       "}\n",
       "\n",
       "a.bh1,  a.bh1:visited, a.bh1:link, a.bh1:active {\n",
       "  text-decoration: none; \n",
       "  color: rgba(0, 0, 0, 0.87);\n",
       "  font-family: 'Roboto','Heebo',Arial,sans-serif;\n",
       "  padding-right: 30px;\n",
       "  font-size:1.1em\n",
       "}\n",
       "a.bh1:hover {\n",
       "  color: rgba(0, 0, 0, 0.57);\n",
       "}\n",
       "    \n",
       "#toc-wrapper {\n",
       "   font-family: 'Roboto','Heebo',Arial,sans-serif;\n",
       "    border: 0px dotted gray;\n",
       "    padding: 10px;\n",
       "    line-height: 1.8em;\n",
       "}    \n",
       "</style>\n",
       "<script>\n",
       "l=\"https://www.ancient-symbols.com/images/wp-image-library/fullsize/infinity.jpg\"\n",
       "l=\"imgs/logo.png\"\n",
       "l=\"\"\n",
       "$('#ipython_notebook').html(`<img src=\"${l}\">`)\n",
       "\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import colabexts\n",
    "from colabexts.jcommon import *\n",
    "\n",
    "jpath=os.path.dirname(colabexts.__file__)\n",
    "jcom = f'{jpath}/jcommon.ipynb'\n",
    "%run $jcom\n",
    "\n",
    "import os, datetime\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython import display\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (16, 5)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "tf.random.set_seed(13)\n",
    "pd.options.display.max_rows = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>rho (g/m**3)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:10:00</th>\n",
       "      <td>-8.02</td>\n",
       "      <td>996.52</td>\n",
       "      <td>1307.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:20:00</th>\n",
       "      <td>-8.41</td>\n",
       "      <td>996.57</td>\n",
       "      <td>1309.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31 23:50:00</th>\n",
       "      <td>-4.23</td>\n",
       "      <td>999.81</td>\n",
       "      <td>1293.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>-4.82</td>\n",
       "      <td>999.82</td>\n",
       "      <td>1296.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420551 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     T (degC)  p (mbar)  rho (g/m**3)\n",
       "Date Time                                            \n",
       "2009-01-01 00:10:00     -8.02    996.52       1307.75\n",
       "2009-01-01 00:20:00     -8.41    996.57       1309.80\n",
       "...                       ...       ...           ...\n",
       "2016-12-31 23:50:00     -4.23    999.81       1293.56\n",
       "2017-01-01 00:00:00     -4.82    999.82       1296.38\n",
       "\n",
       "[420551 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Data\n",
    "#del dfn1\n",
    "if ( \"dfn1\" not in globals()):\n",
    "    csv_path = 'jena_climate_2009_2016.csv.zip'\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['Date Time'] = pd.to_datetime( df['Date Time'] )\n",
    "\n",
    "    dfn1= df[['T (degC)']].copy()\n",
    "    dfn1.index = df['Date Time']\n",
    "\n",
    "    dfn2= df[['T (degC)', 'p (mbar)', 'rho (g/m**3)']].copy()\n",
    "    dfn2.index = df['Date Time']\n",
    "\n",
    "    dfn = dfn2\n",
    "    dfn\n",
    "    \n",
    "dfn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetGen(object):\n",
    "    def __init__(self, targets, nsteps=1):\n",
    "        self.targets = targets\n",
    "        self.nsteps  = nsteps\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets[:-self.nsteps+1 or None])\n",
    "\n",
    "    def getData(self, index):\n",
    "        t = self.targets[index: index + self.nsteps]\n",
    "        return t\n",
    "\n",
    "    def __getitem__( self, key ) :\n",
    "        if isinstance( key, int) or isinstance(key, np.int64 ):\n",
    "            if key < 0: \n",
    "                key += len(self)\n",
    "            if key < 0 or key >= len( self ) :\n",
    "                raise (IndexError, f\"The index (key) is out of range. {len(slef)}\")\n",
    "            return self.getData(key)\n",
    "        if isinstance( key, slice ) :\n",
    "            return [self.targets[ii: ii + self.nsteps] for ii in range(*key.indices(len(self)))]\n",
    "        else:\n",
    "            raise (TypeError, \"Invalid argument type.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>['[-8.02, 996.52, 1307.75] ', '[-8.41, 996.57, 1309.8]  ', '[-8.51, 996.53, 1310.24] ', '[-8.31, 996.51, 1309.19] ', '[-8.27, 996.51, 1309.0]  ']\n",
      "=>['[-8.41, 996.57, 1309.8]  ', '[-8.51, 996.53, 1310.24] ', '[-8.31, 996.51, 1309.19] ', '[-8.27, 996.51, 1309.0]  ', '[-8.05, 996.5, 1307.86]  ']\n",
      "=>['[-8.51, 996.53, 1310.24] ', '[-8.31, 996.51, 1309.19] ', '[-8.27, 996.51, 1309.0]  ', '[-8.05, 996.5, 1307.86]  ', '[-7.62, 996.5, 1305.68]  ']\n",
      "=>['[-8.31, 996.51, 1309.19] ', '[-8.27, 996.51, 1309.0]  ', '[-8.05, 996.5, 1307.86]  ', '[-7.62, 996.5, 1305.68]  ', '[-7.62, 996.5, 1305.69]  ']\n",
      "=>['[-8.27, 996.51, 1309.0]  ', '[-8.05, 996.5, 1307.86]  ', '[-7.62, 996.5, 1305.68]  ', '[-7.62, 996.5, 1305.69]  ', '[-7.91, 996.5, 1307.17]  ']\n",
      "=>['[-8.05, 996.5, 1307.86]  ', '[-7.62, 996.5, 1305.68]  ', '[-7.62, 996.5, 1305.69]  ', '[-7.91, 996.5, 1307.17]  ', '[-8.43, 996.53, 1309.85] ']\n",
      "[[  -8.02  996.52 1307.75]\n",
      " [  -8.41  996.57 1309.8 ]\n",
      " [  -8.51  996.53 1310.24]\n",
      " [  -8.31  996.51 1309.19]\n",
      " [  -8.27  996.51 1309.  ]\n",
      " [  -8.05  996.5  1307.86]\n",
      " [  -7.62  996.5  1305.68]\n",
      " [  -7.62  996.5  1305.69]\n",
      " [  -7.91  996.5  1307.17]\n",
      " [  -8.43  996.53 1309.85]]\n"
     ]
    }
   ],
   "source": [
    "def makestep(a, start, steps=5):\n",
    "    o= []\n",
    "    for i in range(steps):\n",
    "        a1 = a[start+i:-steps+i+1 or None]\n",
    "        o.append(a1)\n",
    "    \n",
    "    return np.hstack([o]).T\n",
    "\n",
    "def makestepTS(a, start, steps=5):\n",
    "    g = TargetGen(a[start:], steps)\n",
    "    return g\n",
    "\n",
    "data=dfn2.values[0:10]\n",
    "g=makestepTS(data,0,5)\n",
    "for i in range(len(g)):\n",
    "    y = g[i]\n",
    "    y1 = [f'{str(list(k)):25}' for k in y]\n",
    "    print(f'=>{y1}')\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This just builds a model Optimizers\n",
    "opt1 = tf.keras.optimizers.RMSprop(clipvalue=1.0)\n",
    " \n",
    " inshape = input shape => #time_steps x #features\n",
    "'''\n",
    "import keras\n",
    "\n",
    "def lstmmodel(inps, inshape, units2=None, nsteps=1, opt=\"adam\", loss=\"mse\", bi=False, dropout=None):\n",
    "    s= inshape\n",
    "    print(locals())\n",
    "    print(f\"Creating LSTM: inuts= {inps} time-steps: {s[0]}, features: {s[1]} #out: {nsteps}\")\n",
    "    m = keras.models.Sequential()\n",
    "\n",
    "    if (bi):\n",
    "        m.add(keras.layers.Bidirectional(\n",
    "            keras.layers.LSTM(inps, return_sequences= (units2 is not None), input_shape=s) ) )\n",
    "    else:\n",
    "        m.add(keras.layers.LSTM(inps, return_sequences= (units2 is not None), input_shape=s) )\n",
    "\n",
    "    if(units2 is not None): #Lets just keep it simple for 2 layers only\n",
    "        m.add(keras.layers.LSTM(units2, activation='relu'))\n",
    "    if (dropout is not None):\n",
    "        m.add( keras.layers.Dropout(dropout) )\n",
    "    m.add(keras.layers.Dense(nsteps))\n",
    "    m.compile(optimizer = opt, loss= loss)\n",
    "    return m\n",
    "\n",
    "def Plot_(y, h, x=None, title=None,**kwargs):\n",
    "    #x = x if x is not None else range(len(y))\n",
    "    plt.plot(y[:,0], marker=\".\", label = \"y\")\n",
    "\n",
    "    if ( len(h.shape) <= 1):\n",
    "        h = h.reshape((len(h), 1))\n",
    "    for i in range(h.shape[-1]):\n",
    "        uy=h[i:,i]\n",
    "        plt.plot(range(i, len(uy)+i), uy, marker=\"x\",  label = f\"$h_{i}$\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.grid(b=\"on\")\n",
    "    plt.legend()\n",
    "    return y1, h1;\n",
    "\n",
    "def modelEqual(m1, m2):\n",
    "    ok = len(m1.layers) ==  len(m2.layers)\n",
    "    if (not ok):\n",
    "        return ok\n",
    "\n",
    "    for l1, l2 in zip(m1.layers, m.layers):\n",
    "        c1, c2 = l1.get_config(), l2.get_config()\n",
    "        tn = c1['name'] \n",
    "        c1['name'] = c2['name'] \n",
    "        ok = c1 == c2 \n",
    "        c1['name'] = tn\n",
    "        if (not ok):\n",
    "            break;\n",
    "    return ok\n",
    "\n",
    "\n",
    "'''\n",
    "NEW NeuralNetwork Class to manage LSTM\n",
    "'''\n",
    "class NNmodel:\n",
    "    def __init__(self, tsParams, model, file=None,  nsteps=1, loadModel=True):\n",
    "        defp =  { \n",
    "                    \"length\":         20,\n",
    "                    \"batch_size\":     256,\n",
    "                    \"stride\":         1,\n",
    "                    \"sampling_rate\" : 1\n",
    "                }\n",
    "        self.model = model\n",
    "        self.tsParam = tsParams or defp\n",
    "        \n",
    "        if( file is not None):\n",
    "            self.model_file=file;\n",
    "            #Load the file and other parameters \n",
    "            if (loadModel and os.path.exists(file)):\n",
    "                m1=self.load()\n",
    "                if modelEqual(self.model,m1) or m is None:\n",
    "                    self.model.set_weights(m1.get_weights()) \n",
    "                    print(f\"Using the loaded model {file}!!\")\n",
    "                else:\n",
    "                    print(\"Models are different, ignoring model loaded from file\")\n",
    "        \n",
    "        self.nsteps= nsteps # nstep predictions\n",
    "    \n",
    "    def setvals(self, d: dict):\n",
    "        for k, v in d.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "    def save(self, file = None):\n",
    "        model_file = file or self.model_file\n",
    "        self.model.save(model_file)\n",
    "\n",
    "    def load(self, file = None):\n",
    "        model_file = file or self.model_file\n",
    "        m = load_model(model_file)\n",
    "        return m\n",
    "\n",
    "    def dump(self):\n",
    "        vr = vars(nnmodel)\n",
    "        for k,v in vr.items():\n",
    "            if type(v) == pd.core.frame.DataFrame:\n",
    "                print(f'{k}: shape:{v.shape}')\n",
    "            else:\n",
    "                print(f'{k}, {type(v)}: {v}')\n",
    "                \n",
    "    # First, do preprocessing which consists of:\n",
    "    # 1. Remove time correlated variables\n",
    "    # 2. Add a time cycle if it makes sense, Suppose a event occurs based on time, then we must have that cycle\n",
    "    # 3. Normalize the data\n",
    "\n",
    "    # *NOTE* we scale only on the training data - *NOT* on the entire dataset\n",
    "    #\n",
    "    def prepare(self, dfn2, pct=0.8, lables=None, lableIndex=0):\n",
    "        data = dfn2\n",
    "        if ( type(dfn2) == pd.core.frame.DataFrame):\n",
    "            data = dfn2.values\n",
    "        \n",
    "        trni = int(len(data) * pct) if (pct < 1) else pct\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        dfs = scaler.fit(data[:trni])\n",
    "        #dfs.mean_, dfs.scale_\n",
    "        dfscaled = (data-dfs.mean_)/dfs.scale_\n",
    "\n",
    "        lables     = lables if lables is not None else dfscaled[:,lableIndex]\n",
    "        #lables     = makestep(lables, 0, self.nsteps)\n",
    "        lables     = makestepTS(lables, 0, self.nsteps)\n",
    "        dfscaled   = dfscaled[:len(lables)]\n",
    "        \n",
    "        trnX, trnY = dfscaled[:trni], lables[:trni]\n",
    "        valX, valY = dfscaled[trni:], lables[trni:]\n",
    "\n",
    "        print(f\"#Training: {trni} samples, Test: {len(valY), len(valX)} samples!\")\n",
    "        \n",
    "        trng    = TimeseriesGenerator(trnX, trnY, **self.tsParam )\n",
    "        valg    = TimeseriesGenerator(valX, valY, **self.tsParam )\n",
    "        \n",
    "        #dfns is the scaled data\n",
    "        self.dfscaled, self.lables, self.lableIndex = dfscaled, lables, lableIndex\n",
    "        self.df, self.trng, self.valg, self.scaler = dfn2, trng,valg, scaler \n",
    "        \n",
    "        return self.dfscaled, self.trng, self.valg, self.scaler \n",
    "               \n",
    "\n",
    "    #We can be smart to add additional new training - not now though\n",
    "    def fit(self,epochs=1, trn=None, val=None):\n",
    "        assert hasattr( self, \"trng\"), \"You must call prepapre!!!\"\n",
    "            \n",
    "        if (trn is None or val is None):\n",
    "            trn,val = self.trng, self.valg\n",
    "            \n",
    "        for i in range(epochs):\n",
    "            self.model.fit(trn, verbose=1, epochs=1, validation_data=val, steps_per_epoch=200, \n",
    "                          validation_steps=50, workers=4, use_multiprocessing=True)\n",
    "   \n",
    "    #Predictions within the traning or valiadation dataset\n",
    "    #\n",
    "    def predict(self, start=0, howmany=100, scaleout=True, title=\"\"):\n",
    "        scaler = self.scaler\n",
    "        tsParams = self.tsParam.copy()\n",
    "        tsParams['batch_size'] = howmany;\n",
    "        \n",
    "        data   = self.dfscaled[start:]\n",
    "        lables = self.lables[start:]\n",
    "        g      = TimeseriesGenerator(data, lables, **tsParams )\n",
    "        \n",
    "        ##\n",
    "        model = self.model\n",
    "        x, y = g[0]\n",
    "        h = model.predict(x)\n",
    "        h1, y1 = h,y\n",
    "        if (scaleout):\n",
    "            h1 = h * scaler.scale_[self.lableIndex]\n",
    "            h1 = h1  + scaler.mean_[self.lableIndex]\n",
    "\n",
    "            y1 = y * scaler.scale_[self.lableIndex]\n",
    "            y1 = y1  + scaler.mean_[self.lableIndex]\n",
    "\n",
    "        return y1, h1\n",
    "\n",
    "    #This is for predicting new data\n",
    "    def prepForPredict(self, dfn2, start=0, howmany=100, lables=None, scaleout=True, title=\"\"):\n",
    "        scaler = self.scaler\n",
    "        tsParams = self.tsParam.copy()\n",
    "        tsParams['batch_size'] = howmany;\n",
    "        \n",
    "        data = dfn2\n",
    "        if ( type(dfn2) == pd.core.frame.DataFrame):\n",
    "            data = dfn2.values\n",
    "        \n",
    "        data   =  (data - scaler.mean_)/scaler.scale_\n",
    "        lables = lables if lables is not None else data[:,self.lableIndex]\n",
    "        lables = makestepTS(lables, 0, self.nsteps)\n",
    "        data   = data[:len(lables)]\n",
    "        \n",
    "        g   = TimeseriesGenerator(dfscaled[start:], lables[start:], **tsParams )\n",
    "        \n",
    "        ##\n",
    "        model = self.model\n",
    "        x, y = g[0]\n",
    "        h = model.predict(x)\n",
    "        h1, y1 = h,y\n",
    "        if (scaleout):\n",
    "            h1 = h * scaler.scale_[self.lableIndex]\n",
    "            h1 = h1  + scaler.mean_[self.lableIndex]\n",
    "\n",
    "            y1 = y * scaler.scale_[self.lableIndex]\n",
    "            y1 = y1  + scaler.mean_[self.lableIndex]\n",
    "\n",
    "        return y1, h1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Training: 5 samples, Test: (4, 4) samples!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.72504983, -0.3592106 , -1.70789837],\n",
       "       [-0.64385663,  1.88585567,  0.713396  ],\n",
       "       [-1.25126854,  0.08980265,  1.23308845],\n",
       "       [-0.03644471, -0.80822386, -0.00708672],\n",
       "       [ 0.20652005, -0.80822386, -0.23149936],\n",
       "       [ 1.54282626, -1.25723711, -1.57797526],\n",
       "       [ 4.15469749, -1.25723711, -4.15281513],\n",
       "       [ 4.15469749, -1.25723711, -4.14100393],\n",
       "       [ 2.39320294, -1.25723711, -2.39294751]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Some test to check the timeSeries Generator\n",
    "tsParams={ \n",
    "    \"length\":         3,\n",
    "    \"batch_size\":     2,\n",
    "    \"stride\":         1,\n",
    "    \"sampling_rate\" : 1\n",
    "}\n",
    "\n",
    "m = None # WE dont care for testing anyway\n",
    "nnmodel1 = NNmodel(tsParams=tsParams, model=m, nsteps=2)\n",
    "data=dfn2.values[0:10]\n",
    "\n",
    "dfscaled, trng, valg, scaler = nnmodel1.prepare(data, pct=.5)\n",
    "dfscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "[[[ 1.72504983 -0.3592106  -1.70789837]\n",
      "  [-0.64385663  1.88585567  0.713396  ]\n",
      "  [-1.25126854  0.08980265  1.23308845]]\n",
      "\n",
      " [[-0.64385663  1.88585567  0.713396  ]\n",
      "  [-1.25126854  0.08980265  1.23308845]\n",
      "  [-0.03644471 -0.80822386 -0.00708672]]] ==>\n",
      "\t\t\t\t\n",
      " [[-0.03644471  0.20652005]\n",
      " [ 0.20652005  1.54282626]]\n",
      "\n",
      "===========Validation set\n",
      "\n",
      "3\n",
      "[[[ 1.54282626 -1.25723711 -1.57797526]\n",
      "  [ 4.15469749 -1.25723711 -4.15281513]\n",
      "  [ 4.15469749 -1.25723711 -4.14100393]]] ==>\n",
      "\t\t\t\t [[ 2.39320294 -0.76533901]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(trng)):\n",
    "    x,y = trng[i]\n",
    "    print(f'{x} ==>\\n\\t\\t\\t\\t\\n {y}')\n",
    "print(\"\\n===========Validation set\\n\")    \n",
    "for i in range(len(valg)):\n",
    "    x,y = valg[i]\n",
    "    print(f'{x} ==>\\n\\t\\t\\t\\t {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.72504983, -0.3592106 , -1.70789837],\n",
       "       [-0.64385663,  1.88585567,  0.713396  ],\n",
       "       [-1.25126854,  0.08980265,  1.23308845],\n",
       "       [-0.03644471, -0.80822386, -0.00708672],\n",
       "       [ 0.20652005, -0.80822386, -0.23149936],\n",
       "       [ 1.54282626, -1.25723711, -1.57797526],\n",
       "       [ 4.15469749, -1.25723711, -4.15281513],\n",
       "       [ 4.15469749, -1.25723711, -4.14100393],\n",
       "       [ 2.39320294, -1.25723711, -2.39294751]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnmodel1.dfscaled[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstmmodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f850b7d83564>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstmmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mse\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mnnmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNNmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsParams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtsParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"m1.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnnmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lstmmodel' is not defined"
     ]
    }
   ],
   "source": [
    "# All steps reusing the functions \n",
    "# Step 1. Read Data here\n",
    "#Lets review the generator output\n",
    "tsParams={ \n",
    "    \"length\":         20,\n",
    "    \"batch_size\":     256,\n",
    "    \"stride\":         1,\n",
    "    \"sampling_rate\" : 1\n",
    "}\n",
    "\n",
    "m = lstmmodel(32, (20,1), units2=None, nsteps=1, opt=\"adam\", loss=\"mse\" )\n",
    "nnmodel1 = NNmodel(tsParams=tsParams, model=m, file=\"m1.h5\")\n",
    "nnmodel1.prepare(dfn1, pct=80000)\n",
    "\n",
    "y1, h1 = nnmodel1.predict(0, 100)\n",
    "o= Plot_(y1, h1, title=\"Initial Weights Predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "for i in range(epochs):\n",
    "    plt.clf()  \n",
    "    y1, h1 = nnmodel1.predict(start=10000, howmany=100)\n",
    "    Plot_( y1, h1, title=f\"{i}\")\n",
    "    plt.show()\n",
    "    nnmodel1.fit()\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    #IPython.display.display(plt.gcf())\n",
    "\n",
    "nnmodel1.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Rate and Stride\n",
    "\n",
    "Just inspect what are the values set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sanity Check to make sure everything is aligned\n",
    "tsParams={ \n",
    "    \"length\":         720,\n",
    "    \"batch_size\":     256,\n",
    "    \"stride\":         1,\n",
    "    \"sampling_rate\" : 6\n",
    "}\n",
    "data   = dfn2.values\n",
    "labels = data[:,0]\n",
    "g = TimeseriesGenerator(data, labels, **tsParams )\n",
    "\n",
    "#Lets review the generator output\n",
    "x, y = g[0]    \n",
    "print(f'{x.shape}, {y.shape} {y[0]}')\n",
    "print(f'X: \\n{x[0][-3:]} <= should match every 6th entry\\n Also: \\n{y[0]} <= 720th entry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check to visually check if X and y correctly aligned\n",
    "# Whenever you see \"<=\" mark, it is aligned at sampling rate of 6\n",
    "\n",
    "dfn3= dfn2.copy()\n",
    "dfn3['idx'] = [i if i % 6 != 0 else f'<={i}' for i in range(len(dfn3))]\n",
    "display(dfn3[700:724])\n",
    "del dfn3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets build a model with multiple features\n",
    "\n",
    "# All steps reusing the functions \n",
    "# Step 1. Read Data here\n",
    "#Lets review the generator output\n",
    "tsParams={ \n",
    "    \"length\":         720,\n",
    "    \"batch_size\":     256,\n",
    "    \"stride\":         1,\n",
    "    \"sampling_rate\" : 6\n",
    "}\n",
    "\n",
    "\n",
    "m = lstmmodel(32, (120,3), units2=None, nsteps=1, opt=\"adam\", loss=\"mse\" )\n",
    "nnmodel1f = NNmodel(tsParams=tsParams, model=m, file=\"m3.h5\")\n",
    "nnmodel1f.prepare(dfn2, pct=80000)\n",
    "\n",
    "y1, h1 = nnmodel1f.predict(0, 100)\n",
    "o=Plot_(y1, h1, title=\"Initial Weights Predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs= 4\n",
    "for i in range(epochs):\n",
    "    plt.clf()  \n",
    "    y1, h1 = nnmodel1f.predict(0, 100)\n",
    "    Plot_( y1, h1, title=f\"{i}\")\n",
    "    plt.show()\n",
    "    nnmodel1f.fit()\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    #IPython.display.display(plt.gcf())\n",
    "nnmodel1f.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the performance with one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets try sampling rate with one feature\n",
    "\n",
    "# All steps reusing the functions \n",
    "# Step 1. Read Data here\n",
    "#Lets review the generator output\n",
    "tsParams={ \n",
    "    \"length\":         720,\n",
    "    \"batch_size\":     256,\n",
    "    \"stride\":         1,\n",
    "    \"sampling_rate\" : 6\n",
    "}\n",
    "\n",
    "m = lstmmodel(32, (120,1), units2=None, nsteps=1, opt=\"adam\", loss=\"mse\" )\n",
    "nnmodel1s = NNmodel(tsParams=tsParams, model=m, file=\"m3-1.h5\")\n",
    "nnmodel1s.prepare(dfn1, pct=80000)\n",
    "\n",
    "y1, h1 = nnmodel1s.predict(0, 100)\n",
    "o=Plot_(y1, h1, title=\"Initial Weights Predictions: sample every 6th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5\n",
    "for i in range(epochs):\n",
    "    plt.clf()  \n",
    "    y1, h1 = nnmodel1s.predict(0, 100)\n",
    "    Plot_( y1, h1, title=f\"{i}\")\n",
    "    plt.show()\n",
    "    nnmodel1s.fit()\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    #IPython.display.display(plt.gcf())\n",
    "\n",
    "nnmodel1s.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s,h = 95000, 100\n",
    "y1, h1 = nnmodel1s.predict(s,h)\n",
    "Plot_( y1, h1, title=f\"{s}-{h}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# MultiVariate Multiple Step Predictions\n",
    "\n",
    "TimeseriesGenerator dont have mechanisms to generate multistep out, we need to prepare the data set as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example Uage of makesteps\n",
    "a=list(range(10))\n",
    "k=makestep(a, 5, 3)\n",
    "a, k.shape, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets build a model with multiple features\n",
    "\n",
    "# All steps reusing the functions \n",
    "# Step 1. Read Data here\n",
    "#Lets review the generator output\n",
    "tsParams={ \n",
    "    \"length\":         720,\n",
    "    \"batch_size\":     256,\n",
    "    \"stride\":         1,\n",
    "    \"sampling_rate\" : 6\n",
    "}\n",
    "\n",
    "nsteps = 5 # 5 predictions\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.0001, clipnorm=1.0, clipvalue=0.5)\n",
    "m = lstmmodel(32, (120,3), units2=32, nsteps=nsteps, opt=opt, loss=\"mse\", dropout=0.5 )\n",
    "nnmodel1mf = NNmodel(tsParams=tsParams, model=m, nsteps=nsteps, file=\"m3-step-5.h5\", loadModel=True)\n",
    "nnmodel1mf.prepare(dfn2, pct=80000)\n",
    "\n",
    "y1,h1 = nnmodel1mf.predict(0, 100, scaleout=True)\n",
    "#o=Plot_(y1, h1, title=\"Initial Weights Predictions-multistep\")\n",
    "o=Plot_(y1, h1, title=\"Initial Weights Predictions: sample every 6th\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=4\n",
    "for i in range(epochs):\n",
    "    plt.clf()  \n",
    "    y1,h1 = nnmodel1mf.predict(0, 100)\n",
    "    Plot_( y1, h1, title=f\"{i}\")\n",
    "    plt.show()\n",
    "    nnmodel1mf.fit(epochs=10)\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    #IPython.display.display(plt.gcf())\n",
    "\n",
    "nnmodel1mf.save();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=nnmodel1mf.model\n",
    "\n",
    "keras.engine.sequential.Sequential.summary(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.get_input_shape_at(0), m.get_output_shape_at(0)\n",
    "for i in range(len(m.layers)):\n",
    "    l = m.layers[i]\n",
    "    s = l.get_input_shape_at(0)\n",
    "    o = l.get_output_shape_at(0)\n",
    "    print(f'{i}=> inp shape: {str(s):15}, out shape: {o}')\n",
    "\n",
    "l.get_output_shape_at(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=m.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(l.get_weights())):\n",
    "    print(l.get_weights()[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 *128 + 32 *128 + 128"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "time_series.ipynb",
   "private_outputs": true,
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "747px",
    "left": "90px",
    "top": "143px",
    "width": "250px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
