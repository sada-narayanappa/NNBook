{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "### References:\n",
    "* http://www.analyticsvidhya.com/blog/2015/09/naive-bayes-explained/\n",
    "* https://egret.psychol.cam.ac.uk/statistics/local_copies_of_sources_Cardinal_and_Aitken_ANOVA/Bayes_theorem.htm#Example_.231:_False_positives_in_a_medical_test\n",
    "\n",
    "\n",
    "#### Some Theory\n",
    "Bayes Theorem\n",
    "\n",
    "$$ P(X|Y) = \\frac{P( X \\cap Y)}{P(Y)} = \\frac{P(Y|X) P(X)}{\\sum_x{P(Y|x)} } $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\" src=\"http://ajax.googleapis.com/ajax/libs/jquery/1.3/jquery.min.js\"></script>\n",
       "<style>\n",
       "body {\n",
       "    font-family: Times 'Merriweather', Georgia, serif;\n",
       "    font-size: 10pt;\n",
       "}\n",
       "\n",
       ".imgs {\n",
       "    width: 250px;\n",
       "    align: left;\n",
       "    float: left;\n",
       "    padding-right: 50px;\n",
       "    padding-top: 20px;\n",
       "    border: 0px gray;\n",
       "}\n",
       ".imgs1 {\n",
       "    align: left;\n",
       "    float: left;\n",
       "    padding-right: 50px;\n",
       "    padding-top: 20px;\n",
       "    border-top: 1px solid gray;\n",
       "    border-bottom: 1px solid gray;\n",
       "    margin-right: 50px;\n",
       "}\n",
       "hr {\n",
       "    height:3px;\n",
       "    border:none;\n",
       "    color:#333;\n",
       "    background-color:#333;\"\n",
       "}\n",
       "p {\n",
       "  margin: 10px auto;\n",
       "  padding: 6px 10px;\n",
       "  font-weight: 300;\n",
       "  font-size: 16px;\n",
       "  line-height: 1.4;\n",
       "}\n",
       "\n",
       "h1 {\n",
       "    margin: 20px auto 0px;\n",
       "    padding: 0 10px;\n",
       "    text-align: center;\n",
       "    font-size: 80px;\n",
       "    ffont-weight: 300;\n",
       "    mmax-width: 800px;\n",
       "}\n",
       "\n",
       "h4 {\n",
       "  max-width: 800px;\n",
       "  margin: 0 auto;\n",
       "  padding: 10px 10px;\n",
       "  font-family: sans-serif;\n",
       "}\n",
       "\n",
       "h5 {\n",
       "    padding-top: 8px;\n",
       "    padding-botton: 8px;\n",
       "    border-top:    1px solid gray;\n",
       "    border-bottom: 2px solid gray;\n",
       "}\n",
       "\n",
       "h6 {\n",
       "    padding-top: 14px;\n",
       "    padding-botton: 16px;\n",
       "    border-top:    2px solid #cccccc;\n",
       "    border-bottom: 2px solid #cccccc;\n",
       "}\n",
       "\n",
       ".thumbnail  {\n",
       "\tposition: relative;\n",
       "\tfloat: left;\n",
       "\tpadding: 0px;\n",
       "\tz-index: 3;\n",
       "}\n",
       "\n",
       ".thumbnail:hover {\n",
       "\tbackground-color: #e9e9e2;\n",
       "\tcolor: #335500;\n",
       "\ttext-decoration: none;\n",
       "}\n",
       "\n",
       ".thumbnail span { /*CSS for enlarged image*/\n",
       "\tposition: fixed;\n",
       "    opacity: 1.5;\n",
       "    background-color: #e5e5e5; \n",
       "\tpadding: 5px;\n",
       "\tborder: 1px solid #666;\n",
       "\tvisibility: hidden;\n",
       "\tcolor: black;\n",
       "\ttext-decoration: none;\n",
       "\ttop:  150px; /* use IF IE6 style to correct IE6 positions of larger image relative to thumb */\n",
       "\tright: 50px;/*position where enlarged image should offset horizontally */\n",
       "\tz-index: 9999;\n",
       "    filter: alpha(opacity=100); \n",
       "}\n",
       "\n",
       ".thumbnail:hover span { /*CSS for enlarged image on hover*/\n",
       "\tvisibility: visible; \n",
       "\twidth: 500px;\n",
       "}\n",
       "    \n",
       ".container { width: 100% !important; }\n",
       "    div.cell{\n",
       "        width:100%;\n",
       "        margin-left:0%;\n",
       "        margin-right:auto;\n",
       "}\n",
       "    \n",
       "div.prompt {display:none}\n",
       "    \n",
       "</style>\n",
       "\n",
       "<script type=\"text/javascript\" src=\"http://ajax.googleapis.com/ajax/libs/jquery/1.3/jquery.min.js\"></script>\n",
       "<script type=\"text/javascript\" src=\"http://d3js.org/d3.v3.min.js\"></script>\n",
       "<script type=\"text/javascript\" src=\"http://d3js.org/topojson.v1.min.js\"></script>\n",
       "<script type=\"text/javascript\" src=\"http://datamaps.github.io/scripts/0.4.0/datamaps.all.js\"></script>\n",
       "\n",
       "<script>\n",
       "function log(e) {\n",
       "    console.log(e)\n",
       "    \n",
       "}\n",
       "\n",
       "function toggleDiv(divId) {\n",
       "   $(\"#\"+divId).toggle();\n",
       "\n",
       "}\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import importlib as imp\n",
    "if ('Jupytils' in sys.modules):\n",
    "    reloaded = imp.reload(Jupytils)\n",
    "else:\n",
    "    import Jupytils\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><td bgcolor=#efefef>768 rows x 9 columns<br><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "        <tr bgcolor=#e6e6fa>\n",
       "      <th bgcolor=#e6e6fa>count</th>\n",
       "      <td>768.000</td>\n",
       "      <td>768.000</td>\n",
       "      <td>768.000</td>\n",
       "      <td>768.000</td>\n",
       "      <td>768.000</td>\n",
       "      <td>768.000</td>\n",
       "      <td>768.000</td>\n",
       "      <td>768.000</td>\n",
       "      <td>768.000</td>\n",
       "    </tr>\n",
       "    <tr bgcolor=#e6e6fa>\n",
       "      <th bgcolor=#e6e6fa>mean</th>\n",
       "      <td>3.845</td>\n",
       "      <td>120.895</td>\n",
       "      <td>69.105</td>\n",
       "      <td>20.536</td>\n",
       "      <td>79.799</td>\n",
       "      <td>31.993</td>\n",
       "      <td>0.472</td>\n",
       "      <td>33.241</td>\n",
       "      <td>0.349</td>\n",
       "    </tr>\n",
       "    <tr bgcolor=#e6e6fa>\n",
       "      <th bgcolor=#e6e6fa>std</th>\n",
       "      <td>3.370</td>\n",
       "      <td>31.973</td>\n",
       "      <td>19.356</td>\n",
       "      <td>15.952</td>\n",
       "      <td>115.244</td>\n",
       "      <td>7.884</td>\n",
       "      <td>0.331</td>\n",
       "      <td>11.760</td>\n",
       "      <td>0.477</td>\n",
       "    </tr>\n",
       "    <tr bgcolor=#e6e6fa>\n",
       "      <th bgcolor=#e6e6fa>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.078</td>\n",
       "      <td>21.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr bgcolor=#dddddd>\n",
       "      <th bgcolor=#6495ed>25%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>62.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27.300</td>\n",
       "      <td>0.244</td>\n",
       "      <td>24.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr bgcolor=#dddddd>\n",
       "      <th bgcolor=#6495ed>50%</th>\n",
       "      <td>3.000</td>\n",
       "      <td>117.000</td>\n",
       "      <td>72.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>30.500</td>\n",
       "      <td>32.000</td>\n",
       "      <td>0.372</td>\n",
       "      <td>29.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr bgcolor=#dddddd>\n",
       "      <th bgcolor=#6495ed>75%</th>\n",
       "      <td>6.000</td>\n",
       "      <td>140.250</td>\n",
       "      <td>80.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>127.250</td>\n",
       "      <td>36.600</td>\n",
       "      <td>0.626</td>\n",
       "      <td>41.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr bgcolor=#dddddd>\n",
       "      <th bgcolor=#6495ed>max</th>\n",
       "      <td>17.000</td>\n",
       "      <td>199.000</td>\n",
       "      <td>122.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>846.000</td>\n",
       "      <td>67.100</td>\n",
       "      <td>2.420</td>\n",
       "      <td>81.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  <tr><td></td><td><a class='thumbnail' href='#thumb'><img src='temp/0x11bcb5c50-Num_Pregnant.png' border=0 style='{margins: 0;}' width=64 height=64 /> <span><img src='temp/0x11bcb5c50-Num_Pregnant.png' /><br /></span></a></td><td><a class='thumbnail' href='#thumb'><img src='temp/0x11bcb5c50-Glucose_c.png' border=0 style='{margins: 0;}' width=64 height=64 /> <span><img src='temp/0x11bcb5c50-Glucose_c.png' /><br /></span></a></td><td><a class='thumbnail' href='#thumb'><img src='temp/0x11bcb5c50-BP.png' border=0 style='{margins: 0;}' width=64 height=64 /> <span><img src='temp/0x11bcb5c50-BP.png' /><br /></span></a></td><td><a class='thumbnail' href='#thumb'><img src='temp/0x11bcb5c50-SkinThick.png' border=0 style='{margins: 0;}' width=64 height=64 /> <span><img src='temp/0x11bcb5c50-SkinThick.png' /><br /></span></a></td><td><a class='thumbnail' href='#thumb'><img src='temp/0x11bcb5c50-Serum_Insulin.png' border=0 style='{margins: 0;}' width=64 height=64 /> <span><img src='temp/0x11bcb5c50-Serum_Insulin.png' /><br /></span></a></td><td><a class='thumbnail' href='#thumb'><img src='temp/0x11bcb5c50-BMI.png' border=0 style='{margins: 0;}' width=64 height=64 /> <span><img src='temp/0x11bcb5c50-BMI.png' /><br /></span></a></td><td><a class='thumbnail' href='#thumb'><img src='temp/0x11bcb5c50-Diabetes.png' border=0 style='{margins: 0;}' width=64 height=64 /> <span><img src='temp/0x11bcb5c50-Diabetes.png' /><br /></span></a></td><td><a class='thumbnail' href='#thumb'><img src='temp/0x11bcb5c50-Age.png' border=0 style='{margins: 0;}' width=64 height=64 /> <span><img src='temp/0x11bcb5c50-Age.png' /><br /></span></a></td><td><a class='thumbnail' href='#thumb'><img src='temp/0x11bcb5c50-Diabetic.png' border=0 style='{margins: 0;}' width=64 height=64 /> <span><img src='temp/0x11bcb5c50-Diabetic.png' /><br /></span></a></td></tr>\n",
       "<tr style=\"text-align: right;\">\n",
       "      <th bgcolor=#6495ed></th>\n",
       "      <th bgcolor=#6495ed>Num_Pregnant\n",
       "\t(int64)</th>\n",
       "      <th bgcolor=#6495ed>Glucose_c\n",
       "\t(int64)</th>\n",
       "      <th bgcolor=#6495ed>BP\n",
       "\t(int64)</th>\n",
       "      <th bgcolor=#6495ed>SkinThick\n",
       "\t(int64)</th>\n",
       "      <th bgcolor=#6495ed>Serum_Insulin\n",
       "\t(int64)</th>\n",
       "      <th bgcolor=#6495ed>BMI\n",
       "\t(float64)</th>\n",
       "      <th bgcolor=#6495ed>Diabetes\n",
       "\t(float64)</th>\n",
       "      <th bgcolor=#6495ed>Age\n",
       "\t(int64)</th>\n",
       "      <th bgcolor=#6495ed>Diabetic\n",
       "\t(int64)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th bgcolor=#6495ed>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.600</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th bgcolor=#6495ed>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.600</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th bgcolor=#6495ed>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.300</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th bgcolor=#6495ed>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.100</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th bgcolor=#6495ed>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.100</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th bgcolor=#6495ed>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.600</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th bgcolor=#6495ed>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.000</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th bgcolor=#6495ed>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.300</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th bgcolor=#6495ed>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.500</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th bgcolor=#6495ed>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th bgcolor=#6495ed>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.600</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th bgcolor=#6495ed>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.000</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></td><td>&nbsp;</td></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fileName=\"../data/pima-indians-diabetes.csv\"\n",
    "\n",
    "df  = LoadDataSet(fileName);\n",
    "displayDFs([df], maxrows=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 768 rows into train=514 and test=254 rows\n",
      "Accuracy: 77.55905511811024%\n"
     ]
    }
   ],
   "source": [
    "# Example of Naive Bayes implemented from Scratch in Python\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"rt\"))\n",
    "    dataset = list(lines)\n",
    "    dataset = dataset[3:]\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset\n",
    "\n",
    "def splitDataset(dataset, splitRatio):\n",
    "\ttrainSize = int(len(dataset) * splitRatio)\n",
    "\ttrainSet = []\n",
    "\ttestSet = list(dataset)\n",
    "\twhile len(trainSet) < trainSize:\n",
    "\t\tindex = random.randrange(len(testSet))\n",
    "\t\ttrainSet.append(testSet.pop(index))\n",
    "\treturn [trainSet, testSet]\n",
    "\n",
    "def separateByClass(dataset):\n",
    "\tseparated = {}\n",
    "\tfor i in range(len(dataset)):\n",
    "\t\tvector = dataset[i]\n",
    "\t\tif (vector[-1] not in separated):\n",
    "\t\t\tseparated[vector[-1]] = []\n",
    "\t\tseparated[vector[-1]].append(vector)\n",
    "\treturn separated\n",
    "\n",
    "def mean(numbers):\n",
    "\treturn sum(numbers)/float(len(numbers))\n",
    "\n",
    "def stdev(numbers):\n",
    "\tavg = mean(numbers)\n",
    "\tvariance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "\treturn math.sqrt(variance)\n",
    "\n",
    "def summarize(dataset):\n",
    "\t#summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "\tsummaries = [(np.array(a).mean(), np.array(a).std(), np.array(a).var()) for a in zip(*dataset)]\n",
    "\tdel summaries[-1]\n",
    "\treturn summaries\n",
    "\n",
    "def summarizeByClass(dataset):\n",
    "    separated = separateByClass(dataset)\n",
    "    summaries = {}\n",
    "    labels={}\n",
    "    y = list(zip(*dataset))[-1]\n",
    "    for classValue, instances in separated.items():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "        labels[classValue] = y.count(classValue)/len(y)\n",
    "    return summaries, labels\n",
    "\n",
    "def calculateProbability(x, mean, stdev, var=None):\n",
    "    if (var is None):\n",
    "        var = math.pow(stdev,2)\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*var)))\n",
    "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
    "\n",
    "def calculateClassProbabilities(summaries, labels, inputVector):\n",
    "\tprobabilities = {}\n",
    "\tfor classValue, classSummaries in summaries.items():\n",
    "\t\tprobabilities[classValue] = labels[classValue]\n",
    "\t\tfor i in range(len(classSummaries)):\n",
    "\t\t\tmean, stdev, var = classSummaries[i]\n",
    "\t\t\tx = inputVector[i]\n",
    "\t\t\tprobabilities[classValue] *= calculateProbability(x, mean, stdev, var)\n",
    "\treturn probabilities\n",
    "\t\t\t\n",
    "def predict(summaries, labels, inputVector):\n",
    "\tprobabilities = calculateClassProbabilities(summaries, labels, inputVector)\n",
    "\tbestLabel, bestProb = None, -1\n",
    "\tfor classValue, probability in probabilities.items():\n",
    "\t\tif bestLabel is None or probability > bestProb:\n",
    "\t\t\tbestProb = probability\n",
    "\t\t\tbestLabel = classValue\n",
    "\treturn bestLabel\n",
    "\n",
    "def getPredictions(summaries, labels, testSet):\n",
    "\tpredictions = []\n",
    "\tfor i in range(len(testSet)):\n",
    "\t\tresult = predict(summaries, labels, testSet[i])\n",
    "\t\tpredictions.append(result)\n",
    "\treturn predictions\n",
    "\n",
    "def getProbs(summaries, labels, testSet):\n",
    "    r = []\n",
    "    for i in range(len(testSet)):\n",
    "        p = calculateClassProbabilities(summaries, labels, testSet[i])\n",
    "        r.append(p)\n",
    "    return r\n",
    "\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "\tcorrect = 0\n",
    "\tfor i in range(len(testSet)):\n",
    "\t\tif testSet[i][-1] == predictions[i]:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "## - Use of locally implemented Naive-Bayes\n",
    "## \n",
    "filename = '../data/pima-indians-diabetes.csv'\n",
    "splitRatio = 0.67\n",
    "dataset = loadCsv(filename)\n",
    "trainingSet, testSet = splitDataset(dataset, splitRatio)\n",
    "print('Split {0} rows into train={1} and test={2} rows'.format(len(dataset), len(trainingSet), len(testSet)) )\n",
    "# prepare model\n",
    "summaries, labels = summarizeByClass(trainingSet)\n",
    "# test model\n",
    "\n",
    "#testSet = testSet[0:50]\n",
    "predictions = getPredictions(summaries, labels, testSet)\n",
    "\n",
    "probs = getProbs(summaries,labels, testSet)\n",
    "accuracy = getAccuracy(testSet, predictions)\n",
    "print('Accuracy: {0}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Python tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def SplitXy(Xy):\n",
    "    Xy10=Xy[0:8]\n",
    "    Xy10 = Xy;\n",
    "    #print Xy10\n",
    "    #print \"========\"\n",
    "    zXy10=list(zip(*Xy10))\n",
    "    y= zXy10[-1]\n",
    "    del zXy10[-1]\n",
    "    z1=zip(*zXy10)\n",
    "    X=[list(t) for t in z1]\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "X,y = SplitXy(trainingSet) \n",
    "Xt,yt = SplitXy(testSet)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0\n",
      "(    3.17      2.95      8.70 )==>  (3.1722054380664653, 2.9493121170600949, 8.6984419638374977)\n",
      "(  110.57     27.97    782.43 )==>  (110.56797583081571, 27.971890321689028, 782.4266481686002)\n",
      "(   68.75     17.40    302.76 )==>  (68.74622356495469, 17.399923844283823, 302.75734978687672)\n",
      "(   19.77     14.71    216.37 )==>  (19.773413897280967, 14.709678467293783, 216.37464061116637)\n",
      "(   73.25    109.02  11885.31 )==>  (73.25377643504531, 109.01978371390005, 11885.313241025548)\n",
      "(   30.47      7.45     55.51 )==>  (30.470996978851968, 7.4503475396941399, 55.507678462226529)\n",
      "(    0.45      0.32      0.10 )==>  (0.44841993957703935, 0.31612071114257823, 0.099932304013289397)\n",
      "(   31.18     12.08    145.97 )==>  (31.17522658610272, 12.081775351475576, 145.96929564352277)\n",
      "Class: 1\n",
      "(    4.87      3.59     12.87 )==>  (4.8743169398907105, 3.5881630608035673, 12.874914150915224)\n",
      "(  141.36     32.28   1042.17 )==>  (141.35519125683061, 32.28272580838177, 1042.1743856191586)\n",
      "(   70.30     19.92    396.66 )==>  (70.295081967213122, 19.91622695270198, 396.65609603153274)\n",
      "(   22.72     17.79    316.45 )==>  (22.721311475409838, 17.789108672192391, 316.45238735107051)\n",
      "(  104.62    141.42  20000.49 )==>  (104.61748633879782, 141.42308002260597, 20000.487563080416)\n",
      "(   34.78      7.12     50.70 )==>  (34.783606557377048, 7.1201901873629261, 50.697108304219299)\n",
      "(    0.57      0.35      0.13 )==>  (0.56932786885245901, 0.35384409156561503, 0.12520564113589536)\n",
      "(   36.98     10.92    119.29 )==>  (36.983606557377051, 10.922216497682697, 119.29481322225209)\n"
     ]
    }
   ],
   "source": [
    "### Compare the models built by Python\n",
    "\n",
    "print (\"Class: 0\")\n",
    "for i,j in enumerate(model.theta_[0]):\n",
    "    print (\"({:8.2f} {:9.2f} {:9.2f} )\".format(j, sqrt(model.sigma_[0][i]), model.sigma_[0][i]) , end=\"\")\n",
    "    print (\"==> \", summaries[0][i])\n",
    "    \n",
    "print (\"Class: 1\")\n",
    "for i,j in enumerate(model.theta_[1]):\n",
    "    print (\"({:8.2f} {:9.2f} {:9.2f} )\".format(j, sqrt(model.sigma_[1][i]), model.sigma_[1][i]) , end=\"\")\n",
    "    print (\"==> \", summaries[1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.11e-01,   6.89e-01],\n",
       "       [  9.77e-01,   2.33e-02],\n",
       "       [  1.17e-03,   9.99e-01],\n",
       "       [  9.72e-01,   2.83e-02],\n",
       "       [  1.07e-05,   1.00e+00],\n",
       "       [  8.38e-01,   1.62e-01],\n",
       "       [  3.51e-01,   6.49e-01],\n",
       "       [  1.25e-02,   9.87e-01],\n",
       "       [  3.00e-01,   7.00e-01],\n",
       "       [  1.32e-01,   8.68e-01]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pt = model.predict_proba(Xt)\n",
    "Pt[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = model.predict(Xt)\n",
    "for i in range(len(predictions)):\n",
    "    if (not predictions[i] == p1[i] ):\n",
    "        print (\"{} differ {} {}, {} \".format(i, predictions[i] , p1[i] , Xt[i]), end=\"\\n\")\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0.0: 1.5144196669021058e-13, 1.0: 3.3504888419796258e-13},\n",
       " {0.0: 2.1659920128183192e-12, 1.0: 5.1652046600474917e-14},\n",
       " {0.0: 2.5252508722759389e-22, 1.0: 2.1583967093423703e-19},\n",
       " {0.0: 1.1955880288636698e-12, 1.0: 3.4878224094673554e-14},\n",
       " {0.0: 5.1180759947852162e-22, 1.0: 4.8008227794786382e-17},\n",
       " {0.0: 5.4594611576568794e-13, 1.0: 1.0549012601765871e-13},\n",
       " {0.0: 7.5881279382433877e-14, 1.0: 1.404839705685913e-13},\n",
       " {0.0: 4.9552646771852525e-16, 1.0: 3.9093638146880608e-14},\n",
       " {0.0: 9.9023505970477623e-14, 1.0: 2.3148834481099243e-13},\n",
       " {0.0: 4.0549065587723969e-16, 1.0: 2.6776226258262385e-15}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329 185 514 0.6400778210116731 0.35992217898832685\n"
     ]
    }
   ],
   "source": [
    "X,y = SplitXy(trainingSet)\n",
    "yy=np.array(y)\n",
    "y0=yy[yy==0]\n",
    "y1=yy[yy==1]\n",
    "p0=len(y0)/len(y)\n",
    "p1=len(y1)/len(y)\n",
    "print(len(y0), len(y1), len(y), p0, p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def predict_log_proba(self, X):\n",
      "        \"\"\"\n",
      "        Return log-probability estimates for the test vector X.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like, shape = [n_samples, n_features]\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        C : array-like, shape = [n_samples, n_classes]\n",
      "            Returns the log-probability of the samples for each class in\n",
      "            the model. The columns correspond to the classes in sorted\n",
      "            order, as they appear in the attribute `classes_`.\n",
      "        \"\"\"\n",
      "        jll = self._joint_log_likelihood(X)\n",
      "        # normalize by P(x) = P(f_1, ..., f_n)\n",
      "        log_prob_x = logsumexp(jll, axis=1)\n",
      "        return jll - np.atleast_2d(log_prob_x).T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dill.source import getsource\n",
    "print(getsource(model.predict_log_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def _joint_log_likelihood(self, X):\n",
      "        check_is_fitted(self, \"classes_\")\n",
      "\n",
      "        X = check_array(X)\n",
      "        joint_log_likelihood = []\n",
      "        for i in range(np.size(self.classes_)):\n",
      "            jointi = np.log(self.class_prior_[i])\n",
      "            n_ij = - 0.5 * np.sum(np.log(2. * np.pi * self.sigma_[i, :]))\n",
      "            n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) /\n",
      "                                 (self.sigma_[i, :]), 1)\n",
      "            joint_log_likelihood.append(jointi + n_ij)\n",
      "\n",
      "        joint_log_likelihood = np.array(joint_log_likelihood).T\n",
      "        return joint_log_likelihood\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(getsource(model._joint_log_likelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.655642023346 0.344357976654\n"
     ]
    }
   ],
   "source": [
    "print(model.class_prior_[0], model.class_prior_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "jll = model._joint_log_likelihood(Xt)\n",
    "#jll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4]\n"
     ]
    }
   ],
   "source": [
    "#Import Library of Gaussian Naive Bayes model\n",
    "\n",
    "#assigning predictor and target variables\n",
    "\n",
    "#Output: ([3,4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.58,  7.  ])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(axis=0)\n",
    "x.var(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x[y==3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My NB : labels => [0 1]\n",
      "Class:  0 \n",
      "  Prior: 0.5833333333333334 \n",
      "  mean: [-1.43  2.43] \n",
      "   var: [ 3.1   5.96]\n",
      "Class:  1 \n",
      "  Prior: 0.4166666666666667 \n",
      "  mean: [-0.2  3.8] \n",
      "   var: [ 5.76  7.36]\n",
      "{0: 0.008217910623911775, 1: 0.007212402228071897, 'Predicted': 0}\n",
      "{0: 0.0007437940158082369, 1: 0.004175793880737992, 'Predicted': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "class myNB:\n",
    "    def __init__(self):\n",
    "        pass;\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        if (type(y) == tuple):\n",
    "            y = np.array(y)\n",
    "        labels = unique(y)\n",
    "        params = defaultdict(dict)\n",
    "        for k in (labels):\n",
    "            x1 = x[y==k]\n",
    "            params[k]['prior'] = len(x1)/len(x)\n",
    "            params[k]['mean'] = x1.mean(axis=0);\n",
    "            params[k]['var' ] = x1.var(axis=0);\n",
    "            \n",
    "        self.labels = labels\n",
    "        self.params = params\n",
    "    \n",
    "    def Gaussian(self, x, mean, var):\n",
    "        e = math.exp(-(math.pow(x-mean,2)/(2*var)))\n",
    "        return (1 / (math.sqrt(2*math.pi * var)) * e)\n",
    "\n",
    "    # Predict product probability \n",
    "    def predict_proba1(self, x):\n",
    "        p = {}\n",
    "        for k, parms in self.params.items():\n",
    "            p[k] = parms['prior']\n",
    "            for i in range(len(parms['mean'])):\n",
    "                mean, var = parms['mean'][i], parms['var'][i]\n",
    "                p[k] *= self.Gaussian( x[i], mean, var)\n",
    "        return p\n",
    "    \n",
    "    def predict_proba(self, Xt, dump=False):\n",
    "        r = []\n",
    "        for x in Xt:\n",
    "            p = self.predict_proba1(x)\n",
    "            w = max(p, key=p.get)\n",
    "            p['Predicted'] = w\n",
    "            r.append(p)\n",
    "        \n",
    "        if (dump):\n",
    "            for i in r:\n",
    "                print(i)\n",
    "        return r;\n",
    "\n",
    "    ## Predict Log probabilities\n",
    "    def predict_log_proba1(self, x):\n",
    "        p = {}\n",
    "        for k, parms in self.params.items():\n",
    "            p[k] = log(parms['prior'])\n",
    "            for i in range(len(parms['mean'])):\n",
    "                mean, var = parms['mean'][i], parms['var'][i]\n",
    "                p[k] += log(self.Gaussian( x[i], mean, var))\n",
    "        return p\n",
    "\n",
    "    def predict_log_proba(self, Xt, dump=False):\n",
    "        r = []\n",
    "        for x in Xt:\n",
    "            p = self.predict_log_proba1(x)\n",
    "            w = max(p, key=p.get)\n",
    "            p['Predicted'] = w\n",
    "            r.append(p)\n",
    "        \n",
    "        if (dump):\n",
    "            for i in r:\n",
    "                print(i)\n",
    "        return r;\n",
    "\n",
    "    def predict(self, Xt, dump=False):\n",
    "        r = predict_proba(Xt, dump)\n",
    "        pass\n",
    "    \n",
    "    def dump(self):\n",
    "        print(\"My NB : labels =>\", self.labels);\n",
    "        for k in self.labels:\n",
    "            p = self.params[k]\n",
    "            print(\"Class: \", k, \"\\n  Prior:\" , p['prior'], \"\\n  mean:\", p['mean'],\"\\n   var:\", p['var']  )\n",
    "            #print(\"{} ==> mean: {:8.2f}  Var: {:9.2f} )\".format(j, self.params[k]) , end=\"\")\n",
    "        pass\n",
    "\n",
    "XX = np.array([[-3,7],[1,5], [1,2], [-2,0], [2,3], [-4,0], [-1,1], [1,1], [-2,2], [2,7], [-4,1], [-2,7]])\n",
    "yy = np.array([0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1])\n",
    "\n",
    "myModel = myNB()\n",
    "\n",
    "# Train the model using the training sets \n",
    "pyModel.fit(XX, yy)\n",
    "                \n",
    "myModel.fit(XX,yy)\n",
    "myModel.dump()\n",
    "\n",
    "predicted_prob= myModel.predict_proba([[1,2],[3,4]], True)\n",
    "\n",
    "#pyModel = GaussianNB()\n",
    "#print (\"Gaussian NB parameters: \")\n",
    "#for k in myModel.labels:\n",
    "#    for i,j in enumerate(pyModel.theta_[k]):\n",
    "        #print (k)\n",
    "#        print (\"{} ({:6.2f} {:6.2f} )\".format(k, j, model.sigma_[k][i]) )\n",
    "    \n",
    "#Predict Output \n",
    "#predicted= model.predict([[1,2],[3,4]])\n",
    "#print( predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My NB : labels => [ 0.  1.]\n",
      "Class:  0.0 \n",
      "  Prior: 0.6556420233463035 \n",
      "  mean: [   3.43  111.7    68.13   18.99   70.73   30.3     0.44   31.62] \n",
      "   var: [  9.79e+00   6.54e+02   3.29e+02   2.23e+02   1.09e+04   5.52e+01   8.95e-02   1.43e+02]\n",
      "Class:  1.0 \n",
      "  Prior: 0.3443579766536965 \n",
      "  mean: [   5.07  141.66   70.95   21.67  102.81   35.06    0.52   37.88] \n",
      "   var: [  1.43e+01   9.31e+02   4.48e+02   3.19e+02   2.25e+04   4.27e+01   1.17e-01   1.25e+02]\n"
     ]
    }
   ],
   "source": [
    "nb = myNB()\n",
    "nb.fit(np.array(X),y)\n",
    "nb.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  0\n",
      "(    3.43      9.79 )==>(    3.43      9.79 )==>(    3.43      9.79 )\n",
      "(  111.70    654.49 )==>(  111.70    654.49 )==>(  111.70    654.49 )\n",
      "(   68.13    329.07 )==>(   68.13    329.07 )==>(   68.13    329.07 )\n",
      "(   18.99    222.55 )==>(   18.99    222.55 )==>(   18.99    222.55 )\n",
      "(   70.73  10906.59 )==>(   70.73  10906.59 )==>(   70.73  10906.59 )\n",
      "(   30.30     55.20 )==>(   30.30     55.20 )==>(   30.30     55.20 )\n",
      "(    0.44      0.09 )==>(    0.44      0.09 )==>(    0.44      0.09 )\n",
      "(   31.62    143.15 )==>(   31.62    143.15 )==>(   31.62    143.15 )\n",
      "Class:  1\n",
      "(    5.07     14.28 )==>(    5.07     14.28 )==>(    5.07     14.28 )\n",
      "(  141.66    931.44 )==>(  141.66    931.44 )==>(  141.66    931.44 )\n",
      "(   70.95    447.60 )==>(   70.95    447.60 )==>(   70.95    447.60 )\n",
      "(   21.67    319.08 )==>(   21.67    319.08 )==>(   21.67    319.08 )\n",
      "(  102.81  22523.10 )==>(  102.81  22523.10 )==>(  102.81  22523.10 )\n",
      "(   35.06     42.65 )==>(   35.06     42.65 )==>(   35.06     42.65 )\n",
      "(    0.52      0.12 )==>(    0.52      0.12 )==>(    0.52      0.12 )\n",
      "(   37.88    125.27 )==>(   37.88    125.27 )==>(   37.88    125.27 )\n"
     ]
    }
   ],
   "source": [
    "### Compare three models built by Google-Link, Sada, Python Lib\n",
    "\n",
    "for k in ([0,1]):\n",
    "    print (\"Class: \", k)\n",
    "    p = nb.params[k];\n",
    "    for i,j in enumerate(model.theta_[k]):\n",
    "        print (\"({:8.2f} {:9.2f} )\".format(j, model.sigma_[k][i]) , end=\"\")\n",
    "        print (\"==>({:8.2f} {:9.2f} )\".format(summaries[k][i][0], summaries[k][i][2] ), end =\"\")\n",
    "        print (\"==>({:8.2f} {:9.2f} )\".format(p['mean'][i], p['var'][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0.0: 1.8105490310301792e-13, 1.0: 3.9635923552404768e-13},\n",
       " {0.0: 1.6017911588647289e-12, 1.0: 3.0058659740266122e-14},\n",
       " {0.0: 8.0099555301913151e-15, 1.0: 2.2423283322909947e-14},\n",
       " {0.0: 1.4055383582267548e-12, 1.0: 1.751120577489116e-14},\n",
       " {0.0: 1.2172910489803623e-12, 1.0: 6.2526182158064153e-14},\n",
       " {0.0: 1.2475447144106206e-14, 1.0: 1.2675705210115209e-13},\n",
       " {0.0: 9.9049665209287208e-16, 1.0: 4.0958959308544996e-16},\n",
       " {0.0: 1.432164938321917e-14, 1.0: 1.8297482185374715e-14},\n",
       " {0.0: 9.9662984049131054e-13, 1.0: 1.0011588795259298e-13},\n",
       " {0.0: 3.5596414848055093e-14, 1.0: 8.5278355615602826e-15},\n",
       " {0.0: 3.0366540148132589e-12, 1.0: 4.0069284408044781e-13},\n",
       " {0.0: 1.2333461433792027e-13, 1.0: 6.0633242379741584e-14},\n",
       " {0.0: 8.8944077295233952e-16, 1.0: 4.4377298569807841e-14},\n",
       " {0.0: 2.992756114209074e-13, 1.0: 2.5031075164434282e-13},\n",
       " {0.0: 5.6984160788679779e-14, 1.0: 1.6793138461726468e-13},\n",
       " {0.0: 2.7655299557307894e-13, 1.0: 3.2582941608865697e-14},\n",
       " {0.0: 1.5902403869405197e-13, 1.0: 1.1983959285508945e-13},\n",
       " {0.0: 5.4693668220858287e-13, 1.0: 5.2583936796896772e-14},\n",
       " {0.0: 1.1999162614561284e-13, 1.0: 2.0584219869846588e-13},\n",
       " {0.0: 2.4287441928228014e-17, 1.0: 5.0367798957580012e-15}]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0.0: 1.8105490310301761e-13, 1.0: 3.963592355240475e-13, 'Predicted': 1.0},\n",
       " {0.0: 1.6017911588647285e-12, 1.0: 3.0058659740266154e-14, 'Predicted': 0.0},\n",
       " {0.0: 8.009955530191307e-15, 1.0: 2.242328332291001e-14, 'Predicted': 1.0},\n",
       " {0.0: 1.4055383582267558e-12, 1.0: 1.751120577489115e-14, 'Predicted': 0.0},\n",
       " {0.0: 1.2172910489803617e-12, 1.0: 6.252618215806427e-14, 'Predicted': 0.0},\n",
       " {0.0: 1.2475447144106209e-14, 1.0: 1.2675705210115207e-13, 'Predicted': 1.0},\n",
       " {0.0: 9.904966520928654e-16, 1.0: 4.0958959308545104e-16, 'Predicted': 0.0},\n",
       " {0.0: 1.4321649383219157e-14, 1.0: 1.8297482185374705e-14, 'Predicted': 1.0},\n",
       " {0.0: 9.966298404913101e-13, 1.0: 1.0011588795259305e-13, 'Predicted': 0.0},\n",
       " {0.0: 3.5596414848055074e-14, 1.0: 8.527835561560272e-15, 'Predicted': 0.0},\n",
       " {0.0: 3.036654014813258e-12, 1.0: 4.006928440804474e-13, 'Predicted': 0.0},\n",
       " {0.0: 1.2333461433792027e-13, 1.0: 6.06332423797416e-14, 'Predicted': 0.0},\n",
       " {0.0: 8.894407729523393e-16, 1.0: 4.4377298569807803e-14, 'Predicted': 1.0},\n",
       " {0.0: 2.992756114209076e-13, 1.0: 2.503107516443426e-13, 'Predicted': 0.0},\n",
       " {0.0: 5.698416078867959e-14, 1.0: 1.6793138461726465e-13, 'Predicted': 1.0},\n",
       " {0.0: 2.7655299557307833e-13, 1.0: 3.258294160886576e-14, 'Predicted': 0.0},\n",
       " {0.0: 1.590240386940518e-13, 1.0: 1.198395928550895e-13, 'Predicted': 0.0},\n",
       " {0.0: 5.469366822085824e-13, 1.0: 5.258393679689677e-14, 'Predicted': 0.0},\n",
       " {0.0: 1.199916261456128e-13, 1.0: 2.058421986984656e-13, 'Predicted': 1.0},\n",
       " {0.0: 2.4287441928227987e-17, 1.0: 5.036779895757993e-15, 'Predicted': 1.0}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{0.0: -29.339976077579863, 1.0: -28.556455434463277, 'Predicted': 1.0},\n",
       " {0.0: -27.159898638536436, 1.0: -31.135625597732005, 'Predicted': 0.0},\n",
       " {0.0: -32.458091185632185, 1.0: -31.428676541828736, 'Predicted': 1.0},\n",
       " {0.0: -27.290600713419785, 1.0: -31.67593538891121, 'Predicted': 0.0},\n",
       " {0.0: -27.434393177696933, 1.0: -30.403191011359496, 'Predicted': 0.0},\n",
       " {0.0: -32.015013910700532, 1.0: -29.696504116108212, 'Predicted': 1.0},\n",
       " {0.0: -34.548325187777223, 1.0: -35.431376007996512, 'Predicted': 0.0},\n",
       " {0.0: -31.877004059618539, 1.0: -31.632012930027717, 'Predicted': 1.0},\n",
       " {0.0: -27.634396967216531, 1.0: -29.932448000379196, 'Predicted': 0.0},\n",
       " {0.0: -30.96653146863925, 1.0: -32.395440809854115, 'Predicted': 0.0},\n",
       " {0.0: -26.520264859695732, 1.0: -28.545581235974478, 'Predicted': 0.0},\n",
       " {0.0: -29.723875291470783, 1.0: -30.433933098115084, 'Predicted': 0.0},\n",
       " {0.0: -34.655938753655462, 1.0: -30.746048349700384, 'Predicted': 1.0},\n",
       " {0.0: -28.83741146876838, 1.0: -29.016073242364165, 'Predicted': 0.0},\n",
       " {0.0: -30.496003046592545, 1.0: -29.415220923832827, 'Predicted': 1.0},\n",
       " {0.0: -28.916373926588403, 1.0: -31.054987507019888, 'Predicted': 0.0},\n",
       " {0.0: -29.469721017362978, 1.0: -29.752622272551672, 'Predicted': 0.0},\n",
       " {0.0: -28.234443353834891, 1.0: -30.57636570589565, 'Predicted': 0.0},\n",
       " {0.0: -29.751354436683421, 1.0: -29.211666545404341, 'Predicted': 1.0},\n",
       " {0.0: -38.256572250206922, 1.0: -32.922009426588936, 'Predicted': 1.0}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1=nb.predict_proba(Xt)\n",
    "p2=nb.predict_log_proba(Xt)\n",
    "display(p1[0:20])\n",
    "display(p2[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31,  0.69],\n",
       "       [ 0.98,  0.02],\n",
       "       [ 0.26,  0.74],\n",
       "       [ 0.99,  0.01],\n",
       "       [ 0.95,  0.05],\n",
       "       [ 0.09,  0.91],\n",
       "       [ 0.71,  0.29],\n",
       "       [ 0.44,  0.56],\n",
       "       [ 0.91,  0.09],\n",
       "       [ 0.81,  0.19],\n",
       "       [ 0.88,  0.12],\n",
       "       [ 0.67,  0.33],\n",
       "       [ 0.02,  0.98],\n",
       "       [ 0.54,  0.46],\n",
       "       [ 0.25,  0.75],\n",
       "       [ 0.89,  0.11],\n",
       "       [ 0.57,  0.43],\n",
       "       [ 0.91,  0.09],\n",
       "       [ 0.37,  0.63],\n",
       "       [ 0.  ,  1.  ]])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pt = model.predict_proba(Xt)\n",
    "Pt[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-29.34, -28.56],\n",
       "       [-27.16, -31.14],\n",
       "       [-32.46, -31.43],\n",
       "       [-27.29, -31.68],\n",
       "       [-27.43, -30.4 ],\n",
       "       [-32.02, -29.7 ],\n",
       "       [-34.55, -35.43],\n",
       "       [-31.88, -31.63],\n",
       "       [-27.63, -29.93],\n",
       "       [-30.97, -32.4 ],\n",
       "       [-26.52, -28.55],\n",
       "       [-29.72, -30.43],\n",
       "       [-34.66, -30.75],\n",
       "       [-28.84, -29.02],\n",
       "       [-30.5 , -29.42],\n",
       "       [-28.92, -31.05],\n",
       "       [-29.47, -29.75],\n",
       "       [-28.23, -30.58],\n",
       "       [-29.75, -29.21],\n",
       "       [-38.26, -32.92]])"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jll = model._joint_log_likelihood(Xt)\n",
    "jll[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -57.9 ],\n",
       "       [ -58.3 ],\n",
       "       [ -63.89],\n",
       "       [ -58.97],\n",
       "       [ -57.84],\n",
       "       [ -61.71],\n",
       "       [ -69.98],\n",
       "       [ -63.51],\n",
       "       [ -57.57],\n",
       "       [ -63.36],\n",
       "       [ -55.07],\n",
       "       [ -60.16],\n",
       "       [ -65.4 ],\n",
       "       [ -57.85],\n",
       "       [ -59.91],\n",
       "       [ -59.97],\n",
       "       [ -59.22],\n",
       "       [ -58.81],\n",
       "       [ -58.96],\n",
       "       [ -71.18],\n",
       "       [ -83.24],\n",
       "       [ -60.17],\n",
       "       [ -60.71],\n",
       "       [ -65.42],\n",
       "       [ -95.07],\n",
       "       [ -63.65],\n",
       "       [ -56.69],\n",
       "       [ -56.9 ],\n",
       "       [ -72.93],\n",
       "       [ -60.86],\n",
       "       [ -57.99],\n",
       "       [ -65.63],\n",
       "       [ -55.7 ],\n",
       "       [ -66.44],\n",
       "       [ -57.96],\n",
       "       [ -65.39],\n",
       "       [ -54.64],\n",
       "       [ -63.23],\n",
       "       [ -58.23],\n",
       "       [ -59.08],\n",
       "       [ -61.43],\n",
       "       [ -58.44],\n",
       "       [ -68.25],\n",
       "       [ -55.55],\n",
       "       [ -59.56],\n",
       "       [ -58.13],\n",
       "       [ -57.  ],\n",
       "       [ -72.01],\n",
       "       [ -55.93],\n",
       "       [ -56.52],\n",
       "       [ -64.79],\n",
       "       [ -62.2 ],\n",
       "       [ -65.02],\n",
       "       [ -60.46],\n",
       "       [ -63.78],\n",
       "       [ -71.58],\n",
       "       [ -68.62],\n",
       "       [ -65.08],\n",
       "       [ -58.99],\n",
       "       [ -57.95],\n",
       "       [ -58.39],\n",
       "       [ -57.07],\n",
       "       [ -56.4 ],\n",
       "       [ -56.  ],\n",
       "       [ -54.66],\n",
       "       [ -57.64],\n",
       "       [ -61.44],\n",
       "       [ -58.59],\n",
       "       [ -87.17],\n",
       "       [ -61.18],\n",
       "       [ -77.07],\n",
       "       [ -65.44],\n",
       "       [ -60.9 ],\n",
       "       [ -59.7 ],\n",
       "       [ -61.05],\n",
       "       [ -57.54],\n",
       "       [ -61.18],\n",
       "       [ -64.2 ],\n",
       "       [ -62.12],\n",
       "       [ -57.06],\n",
       "       [ -59.61],\n",
       "       [ -56.82],\n",
       "       [ -59.03],\n",
       "       [ -63.78],\n",
       "       [ -59.37],\n",
       "       [ -66.46],\n",
       "       [ -57.46],\n",
       "       [ -57.12],\n",
       "       [ -60.18],\n",
       "       [ -58.92],\n",
       "       [ -58.62],\n",
       "       [ -57.38],\n",
       "       [ -61.56],\n",
       "       [ -58.71],\n",
       "       [ -56.28],\n",
       "       [ -60.97],\n",
       "       [ -58.13],\n",
       "       [ -59.05],\n",
       "       [ -60.93],\n",
       "       [ -57.74],\n",
       "       [ -63.85],\n",
       "       [ -69.57],\n",
       "       [ -62.07],\n",
       "       [ -59.89],\n",
       "       [ -57.09],\n",
       "       [ -59.63],\n",
       "       [ -64.9 ],\n",
       "       [ -56.66],\n",
       "       [ -59.58],\n",
       "       [ -56.62],\n",
       "       [ -57.88],\n",
       "       [ -61.91],\n",
       "       [ -68.27],\n",
       "       [ -75.99],\n",
       "       [ -57.03],\n",
       "       [ -77.09],\n",
       "       [ -56.81],\n",
       "       [ -76.5 ],\n",
       "       [ -57.1 ],\n",
       "       [ -60.14],\n",
       "       [ -64.35],\n",
       "       [ -64.74],\n",
       "       [ -61.22],\n",
       "       [ -59.13],\n",
       "       [ -94.86],\n",
       "       [ -57.73],\n",
       "       [ -59.17],\n",
       "       [ -65.35],\n",
       "       [ -61.06],\n",
       "       [ -61.56],\n",
       "       [ -57.12],\n",
       "       [ -56.8 ],\n",
       "       [ -56.44],\n",
       "       [ -61.74],\n",
       "       [ -62.13],\n",
       "       [ -60.4 ],\n",
       "       [ -70.11],\n",
       "       [ -65.73],\n",
       "       [ -57.86],\n",
       "       [ -61.59],\n",
       "       [ -60.97],\n",
       "       [ -63.32],\n",
       "       [ -94.69],\n",
       "       [ -62.22],\n",
       "       [ -59.67],\n",
       "       [-119.2 ],\n",
       "       [ -83.93],\n",
       "       [ -56.97],\n",
       "       [ -67.63],\n",
       "       [ -60.78],\n",
       "       [ -63.44],\n",
       "       [ -61.84],\n",
       "       [ -61.31],\n",
       "       [ -59.29],\n",
       "       [ -59.09],\n",
       "       [ -62.03],\n",
       "       [ -60.01],\n",
       "       [ -58.61],\n",
       "       [ -57.2 ],\n",
       "       [ -60.34],\n",
       "       [ -73.24],\n",
       "       [ -56.73],\n",
       "       [ -57.91],\n",
       "       [ -58.22],\n",
       "       [ -57.17],\n",
       "       [ -59.26],\n",
       "       [ -66.58],\n",
       "       [ -67.02],\n",
       "       [ -62.63],\n",
       "       [ -64.79],\n",
       "       [ -63.41],\n",
       "       [ -58.17],\n",
       "       [ -56.54],\n",
       "       [ -66.75],\n",
       "       [ -61.49],\n",
       "       [ -55.67],\n",
       "       [ -92.7 ],\n",
       "       [ -57.98],\n",
       "       [ -57.12],\n",
       "       [ -70.32],\n",
       "       [ -65.05],\n",
       "       [ -61.36],\n",
       "       [ -60.13],\n",
       "       [ -55.17],\n",
       "       [ -64.34],\n",
       "       [ -59.48],\n",
       "       [ -68.06],\n",
       "       [ -55.48],\n",
       "       [ -58.01],\n",
       "       [ -57.7 ],\n",
       "       [ -57.37],\n",
       "       [ -58.32],\n",
       "       [ -58.7 ],\n",
       "       [ -62.19],\n",
       "       [ -67.05],\n",
       "       [ -59.39],\n",
       "       [ -56.71],\n",
       "       [ -56.33],\n",
       "       [ -60.28],\n",
       "       [ -65.24],\n",
       "       [ -76.94],\n",
       "       [ -60.63],\n",
       "       [ -63.36],\n",
       "       [ -63.74],\n",
       "       [ -72.06],\n",
       "       [ -57.58],\n",
       "       [ -58.37],\n",
       "       [ -71.72],\n",
       "       [ -72.62],\n",
       "       [ -59.68],\n",
       "       [ -58.83],\n",
       "       [ -57.84],\n",
       "       [ -58.88],\n",
       "       [ -58.6 ],\n",
       "       [ -58.75],\n",
       "       [ -56.73],\n",
       "       [ -59.12],\n",
       "       [ -60.72],\n",
       "       [ -59.3 ],\n",
       "       [ -60.71],\n",
       "       [ -64.35],\n",
       "       [ -64.22],\n",
       "       [ -59.34],\n",
       "       [ -58.46],\n",
       "       [ -73.91],\n",
       "       [ -67.17],\n",
       "       [ -58.6 ],\n",
       "       [ -60.21],\n",
       "       [ -63.85],\n",
       "       [ -61.78],\n",
       "       [ -56.4 ],\n",
       "       [ -68.53],\n",
       "       [ -60.81],\n",
       "       [ -57.17],\n",
       "       [ -60.33],\n",
       "       [ -94.59],\n",
       "       [ -63.1 ],\n",
       "       [ -61.  ],\n",
       "       [ -61.67],\n",
       "       [ -59.24],\n",
       "       [ -63.84],\n",
       "       [ -57.13],\n",
       "       [ -60.98],\n",
       "       [ -56.74],\n",
       "       [ -58.67],\n",
       "       [ -57.46],\n",
       "       [ -64.96],\n",
       "       [ -62.02],\n",
       "       [ -62.04],\n",
       "       [ -57.55],\n",
       "       [ -57.05],\n",
       "       [ -58.72],\n",
       "       [ -67.81],\n",
       "       [ -55.44]])"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=sum(jll,1)\n",
    "sum(jll,1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-28.18, -27.14, -31.12, -27.28, -27.38, -29.6 , -34.2 , -31.05, -27.54, -30.75, -26.4 , -29.32, -30.73, -28.23, -29.12, -28.8 , -28.91, -28.14, -28.75, -32.92])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob_x = scipy.misc.logsumexp(jll, axis=1)\n",
    "log_prob_x[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.16e+00,  -3.76e-01],\n",
       "       [ -1.86e-02,  -3.99e+00],\n",
       "       [ -1.33e+00,  -3.05e-01],\n",
       "       [ -1.24e-02,  -4.40e+00],\n",
       "       [ -5.01e-02,  -3.02e+00],\n",
       "       [ -2.41e+00,  -9.39e-02],\n",
       "       [ -3.46e-01,  -1.23e+00],\n",
       "       [ -8.23e-01,  -5.78e-01],\n",
       "       [ -9.57e-02,  -2.39e+00],\n",
       "       [ -2.15e-01,  -1.64e+00],\n",
       "       [ -1.24e-01,  -2.15e+00],\n",
       "       [ -4.00e-01,  -1.11e+00],\n",
       "       [ -3.93e+00,  -1.98e-02],\n",
       "       [ -6.08e-01,  -7.86e-01],\n",
       "       [ -1.37e+00,  -2.92e-01],\n",
       "       [ -1.11e-01,  -2.25e+00],\n",
       "       [ -5.62e-01,  -8.45e-01],\n",
       "       [ -9.18e-02,  -2.43e+00],\n",
       "       [ -9.99e-01,  -4.59e-01],\n",
       "       [ -5.34e+00,  -4.81e-03]])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps= jll - np.atleast_2d(log_prob_x).T\n",
    "ps[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31,  0.69],\n",
       "       [ 0.98,  0.02],\n",
       "       [ 0.26,  0.74],\n",
       "       [ 0.99,  0.01],\n",
       "       [ 0.95,  0.05],\n",
       "       [ 0.09,  0.91],\n",
       "       [ 0.71,  0.29],\n",
       "       [ 0.44,  0.56],\n",
       "       [ 0.91,  0.09],\n",
       "       [ 0.81,  0.19],\n",
       "       [ 0.88,  0.12],\n",
       "       [ 0.67,  0.33],\n",
       "       [ 0.02,  0.98],\n",
       "       [ 0.54,  0.46],\n",
       "       [ 0.25,  0.75],\n",
       "       [ 0.89,  0.11],\n",
       "       [ 0.57,  0.43],\n",
       "       [ 0.91,  0.09],\n",
       "       [ 0.37,  0.63],\n",
       "       [ 0.  ,  1.  ]])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(ps[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
